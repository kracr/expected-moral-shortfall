{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "626513c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, confusion_matrix, classification_report, log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5b5600",
   "metadata": {},
   "source": [
    "# Experiment 1 - Simple Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5c0254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def esa_score(phi, alpha):\n",
    "    return np.dot(alpha, phi)\n",
    "\n",
    "def threshold_crossing_rate(esa_baseline, esa_moral, tau):\n",
    "    crossed = (esa_baseline < tau) & (esa_moral >= tau)\n",
    "    return np.mean(crossed)\n",
    "\n",
    "def moral_win_rate(esa_baseline, esa_moral):\n",
    "    return np.mean(esa_moral > esa_baseline)\n",
    "\n",
    "def esa_difference(esa_baseline, esa_moral):\n",
    "    return np.mean(esa_moral - esa_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e25a491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(y_true, y_pred):\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'f1_score': f1_score(y_true, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_true, y_pred)\n",
    "    }\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    return metrics\n",
    "\n",
    "def evaluate_esa_metrics(esa_baseline, esa_moral, tau):\n",
    "    return {\n",
    "        'esa_diff': esa_difference(esa_baseline, esa_moral),\n",
    "        'tcr': threshold_crossing_rate(esa_baseline, esa_moral, tau),\n",
    "        'moral_win_rate': moral_win_rate(esa_baseline, esa_moral)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "906a5032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Baseline Accuracy: 0.811042944785276\n",
      "Fold 2 Baseline Accuracy: 0.7937384898710865\n",
      "Fold 3 Baseline Accuracy: 0.805402087170043\n",
      "Fold 4 Baseline Accuracy: 0.8047882136279927\n",
      "Fold 5 Baseline Accuracy: 0.8004910988336402\n",
      "Fold 6 Baseline Accuracy: 0.8029465930018416\n",
      "Fold 7 Baseline Accuracy: 0.8103130755064457\n",
      "Fold 8 Baseline Accuracy: 0.807243707796194\n",
      "Fold 9 Baseline Accuracy: 0.809085328422345\n",
      "Fold 10 Baseline Accuracy: 0.809085328422345\n",
      "Fold 11 Baseline Accuracy: 0.7961939840392879\n",
      "Fold 12 Baseline Accuracy: 0.8035604665438919\n",
      "Fold 13 Baseline Accuracy: 0.8041743400859422\n",
      "Fold 14 Baseline Accuracy: 0.809085328422345\n",
      "Fold 15 Baseline Accuracy: 0.8041743400859422\n",
      "Fold 16 Baseline Accuracy: 0.8011049723756906\n",
      "Fold 17 Baseline Accuracy: 0.7992633517495396\n",
      "Fold 18 Baseline Accuracy: 0.8084714548802947\n",
      "Fold 19 Baseline Accuracy: 0.7986494782074892\n",
      "Fold 20 Baseline Accuracy: 0.8066298342541437\n",
      "\n",
      "Logistic Regression Baseline\n",
      "Baseline Accuracy: 0.8042724287161229\n",
      "Time taken: 1.779093 seconds\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89     25473\n",
      "           1       0.73      0.16      0.27      7108\n",
      "\n",
      "    accuracy                           0.80     32581\n",
      "   macro avg       0.77      0.57      0.58     32581\n",
      "weighted avg       0.79      0.80      0.75     32581\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[25046   427]\n",
      " [ 5950  1158]]\n",
      "{'accuracy': 0.8042724287161229, 'precision': 0.7305993690851735, 'recall': 0.16291502532357907, 'f1_score': 0.2664212584838376, 'roc_auc': 0.5730760891938039}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #read orig dataset\n",
    "    df = pd.read_csv('credit_risk_dataset.csv')\n",
    "    \n",
    "    # Initialize LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    \n",
    "    # Apply label encoding\n",
    "    df['person_home_ownership'] = label_encoder.fit_transform(df['person_home_ownership'])\n",
    "    df['loan_intent'] = label_encoder.fit_transform(df['loan_intent'])\n",
    "    df['loan_grade'] = label_encoder.fit_transform(df['loan_grade'])\n",
    "    df['cb_person_default_on_file'] = label_encoder.fit_transform(df['cb_person_default_on_file'])\n",
    "    \n",
    "    y = df['loan_status']\n",
    "    X = df.drop(columns=['loan_status'])\n",
    "\n",
    "    n_splits = 20\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    preds = np.zeros(len(X))\n",
    "\n",
    "    #start timer\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        preds[val_idx] = y_val_pred\n",
    "\n",
    "        print(f\"Fold {fold+1} Baseline Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "\n",
    "    #end time\n",
    "    end_time = time.perf_counter()\n",
    "    \n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    print(\"\\nLogistic Regression Baseline\")\n",
    "    print(\"Baseline Accuracy:\", accuracy_score(y, preds))\n",
    "    print(f\"Time taken: {elapsed_time:.6f} seconds\")\n",
    "    \n",
    "    metrics = evaluate_classification(y, preds)\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86cac038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., ..., 1., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "651be127",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('out.txt', y_val, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b043f3a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "096c1f5c",
   "metadata": {},
   "source": [
    "# Experiment 2 - Logistic Regression on ESA-augmented Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f85bf15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 ESA-Augmented Accuracy: 0.811042944785276\n",
      "Fold 2 ESA-Augmented Accuracy: 0.7937384898710865\n",
      "Fold 3 ESA-Augmented Accuracy: 0.805402087170043\n",
      "Fold 4 ESA-Augmented Accuracy: 0.8047882136279927\n",
      "Fold 5 ESA-Augmented Accuracy: 0.8004910988336402\n",
      "Fold 6 ESA-Augmented Accuracy: 0.8029465930018416\n",
      "Fold 7 ESA-Augmented Accuracy: 0.8103130755064457\n",
      "Fold 8 ESA-Augmented Accuracy: 0.807243707796194\n",
      "Fold 9 ESA-Augmented Accuracy: 0.809085328422345\n",
      "Fold 10 ESA-Augmented Accuracy: 0.809085328422345\n",
      "Fold 11 ESA-Augmented Accuracy: 0.7961939840392879\n",
      "Fold 12 ESA-Augmented Accuracy: 0.8035604665438919\n",
      "Fold 13 ESA-Augmented Accuracy: 0.8041743400859422\n",
      "Fold 14 ESA-Augmented Accuracy: 0.809085328422345\n",
      "Fold 15 ESA-Augmented Accuracy: 0.8041743400859422\n",
      "Fold 16 ESA-Augmented Accuracy: 0.8011049723756906\n",
      "Fold 17 ESA-Augmented Accuracy: 0.7992633517495396\n",
      "Fold 18 ESA-Augmented Accuracy: 0.8084714548802947\n",
      "Fold 19 ESA-Augmented Accuracy: 0.7986494782074892\n",
      "Fold 20 ESA-Augmented Accuracy: 0.8066298342541437\n",
      "\n",
      "Logistic Regression ESA-Augmented\n",
      "Accuracy: 0.8042724287161229\n",
      "Time taken: 2.197170 seconds\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89     25473\n",
      "           1       0.73      0.16      0.27      7108\n",
      "\n",
      "    accuracy                           0.80     32581\n",
      "   macro avg       0.77      0.57      0.58     32581\n",
      "weighted avg       0.79      0.80      0.75     32581\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[25046   427]\n",
      " [ 5950  1158]]\n",
      "{'accuracy': 0.8042724287161229, 'precision': 0.7305993690851735, 'recall': 0.16291502532357907, 'f1_score': 0.2664212584838376, 'roc_auc': 0.5730760891938039}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #read orig dataset\n",
    "    df2 = pd.read_csv('credit_risk_dataset - ethics.csv')\n",
    "    \n",
    "    # Initialize LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    \n",
    "    # Apply label encoding\n",
    "    df2['person_home_ownership'] = label_encoder.fit_transform(df2['person_home_ownership'])\n",
    "    df2['loan_intent'] = label_encoder.fit_transform(df2['loan_intent'])\n",
    "    df2['loan_grade'] = label_encoder.fit_transform(df2['loan_grade'])\n",
    "    df2['cb_person_default_on_file'] = label_encoder.fit_transform(df2['cb_person_default_on_file'])\n",
    "    \n",
    "    y = df2['loan_status']\n",
    "    X = df2.drop(columns=['loan_status'])\n",
    "\n",
    "    n_splits = 20\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    preds = np.zeros(len(X))\n",
    "\n",
    "    #start timer\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        preds[val_idx] = y_val_pred\n",
    "\n",
    "        print(f\"Fold {fold+1} ESA-Augmented Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "\n",
    "    #end time\n",
    "    end_time = time.perf_counter()\n",
    "    \n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    print(\"\\nLogistic Regression ESA-Augmented\")\n",
    "    print(\"Accuracy:\", accuracy_score(y, preds))\n",
    "    print(f\"Time taken: {elapsed_time:.6f} seconds\")\n",
    "    \n",
    "    metrics = evaluate_classification(y, preds)\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0729515",
   "metadata": {},
   "source": [
    "# Experiment 3 - Logistic Regression on ESA-augmented Dataset with CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53cec905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, confusion_matrix, classification_report, log_loss\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44c2b497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(y_true, y_pred):\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'f1_score': f1_score(y_true, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_true, y_pred)\n",
    "    }\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    return metrics\n",
    "\n",
    "def evaluate_regression(y_true, y_pred):\n",
    "    return {\n",
    "        'mse': mean_squared_error(y_true, y_pred),\n",
    "        'rmse': mean_squared_error(y_true, y_pred, squared=False)\n",
    "    }\n",
    "\n",
    "def evaluate_esa_metrics(esa_baseline, esa_moral, tau):\n",
    "    return {\n",
    "        'esa_diff': esa_difference(esa_baseline, esa_moral),\n",
    "        'tcr': threshold_crossing_rate(esa_baseline, esa_moral, tau),\n",
    "        'moral_win_rate': moral_win_rate(esa_baseline, esa_moral)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9e182b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_esa_decision_function(model, X, phi_matrix, alpha, tau_values):\n",
    "    y_proba = model.predict_proba(X)[:, 1]\n",
    "    y_pred = model.predict(X)\n",
    "    esa_scores = np.array([esa_score(phi, alpha) for phi in phi_matrix])\n",
    "    loan_status_moral = (esa_scores >= tau_values).astype(int)\n",
    "\n",
    "    eval_moral = evaluate_classification(y_pred, loan_status_moral)\n",
    "    eval_moral['roc_auc'] = roc_auc_score(y_pred, loan_status_moral)\n",
    "    return eval_moral, esa_scores, loan_status_moral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17036331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.83      5457\n",
      "           1       0.27      0.38      0.31      1060\n",
      "\n",
      "    accuracy                           0.73      6517\n",
      "   macro avg       0.57      0.59      0.57      6517\n",
      "weighted avg       0.77      0.73      0.75      6517\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4349 1108]\n",
      " [ 657  403]]\n",
      "Fold 1: {'accuracy': 0.7291698634340954, 'precision': 0.26671078755790867, 'recall': 0.38018867924528305, 'f1_score': 0.31349669389342666, 'roc_auc': 0.588573357397976}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.83      5441\n",
      "           1       0.27      0.38      0.32      1075\n",
      "\n",
      "    accuracy                           0.73      6516\n",
      "   macro avg       0.57      0.59      0.57      6516\n",
      "weighted avg       0.77      0.73      0.75      6516\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4351 1090]\n",
      " [ 666  409]]\n",
      "Fold 2: {'accuracy': 0.7305095150399018, 'precision': 0.27284856571047367, 'recall': 0.38046511627906976, 'f1_score': 0.31779331779331776, 'roc_auc': 0.5900671473694559}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84      5442\n",
      "           1       0.27      0.36      0.31      1074\n",
      "\n",
      "    accuracy                           0.74      6516\n",
      "   macro avg       0.57      0.59      0.57      6516\n",
      "weighted avg       0.77      0.74      0.75      6516\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4409 1033]\n",
      " [ 687  387]]\n",
      "Fold 3: {'accuracy': 0.7360343769183548, 'precision': 0.27253521126760566, 'recall': 0.36033519553072624, 'f1_score': 0.3103448275862069, 'roc_auc': 0.585257638191677}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.83      5461\n",
      "           1       0.25      0.34      0.29      1055\n",
      "\n",
      "    accuracy                           0.73      6516\n",
      "   macro avg       0.56      0.57      0.56      6516\n",
      "weighted avg       0.76      0.73      0.75      6516\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4397 1064]\n",
      " [ 696  359]]\n",
      "Fold 4: {'accuracy': 0.7298956414978515, 'precision': 0.2522839072382291, 'recall': 0.3402843601895735, 'f1_score': 0.28974979822437447, 'roc_auc': 0.5727241247935598}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83      5407\n",
      "           1       0.26      0.36      0.30      1109\n",
      "\n",
      "    accuracy                           0.72      6516\n",
      "   macro avg       0.56      0.58      0.57      6516\n",
      "weighted avg       0.76      0.72      0.74      6516\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4305 1102]\n",
      " [ 712  397]]\n",
      "Fold 5: {'accuracy': 0.7216083486801719, 'precision': 0.2648432288192128, 'recall': 0.3579801623083859, 'f1_score': 0.3044478527607362, 'roc_auc': 0.5770851431109156}\n",
      "\n",
      "--- Final Evaluation ---\n",
      "Standard Accuracy: 0.9364967312237193\n",
      "Moral Accuracy: 0.6946686719253553\n",
      "Moral Agreement: 0.729443540713913\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     25473\n",
      "           1       0.97      0.73      0.83      7108\n",
      "\n",
      "    accuracy                           0.94     32581\n",
      "   macro avg       0.95      0.86      0.90     32581\n",
      "weighted avg       0.94      0.94      0.93     32581\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[25306   167]\n",
      " [ 1902  5206]]\n",
      "{'accuracy': 0.9364967312237193, 'precision': 0.9689186674111298, 'recall': 0.7324141812042769, 'f1_score': 0.8342280266004327, 'roc_auc': 0.8629291099952212}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Example dummy ESA weights\n",
    "    alpha = np.array([0.4, 0.2, 0.3, 0.0, 0.0, 0.1])  # For consequentialism\n",
    "\n",
    "    # Load data (replace this with your actual DataFrame)\n",
    "    df = pd.read_csv('credit_risk_dataset - ethics.csv')  # Assumes 6 ESA features + CST + loan_status + other inputs\n",
    "\n",
    "    # Initialize LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    # Apply label encoding\n",
    "    df['person_home_ownership'] = label_encoder.fit_transform(df['person_home_ownership'])\n",
    "    df['loan_intent'] = label_encoder.fit_transform(df['loan_intent'])\n",
    "    df['loan_grade'] = label_encoder.fit_transform(df['loan_grade'])\n",
    "    df['cb_person_default_on_file'] = label_encoder.fit_transform(df['cb_person_default_on_file'])\n",
    "    \n",
    "    # Extract ESA features and CST\n",
    "    esa_features = df[['severity_cons','dur_cons','util_cons','prin_up','prin_vi','moral_int']].values\n",
    "    tau_values = df['CST'].values\n",
    "    y = df['loan_status']\n",
    "    X = df.drop(columns=['loan_status', 'CST', 'severity_cons','dur_cons','util_cons','prin_up','prin_vi','moral_int'])\n",
    "\n",
    "    n_splits = 5\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    catboost_params = {\n",
    "        'depth': 7,\n",
    "        'learning_rate': 0.19893301995319765,\n",
    "        'bagging_temperature': 0.7979373495258176,\n",
    "        'l2_leaf_reg': 5,\n",
    "        'loss_function': 'Logloss',\n",
    "        'iterations': 400,\n",
    "        'grow_policy': 'Lossguide',\n",
    "        'eval_metric': 'AUC',\n",
    "        'verbose': False\n",
    "    }\n",
    "\n",
    "    preds = np.zeros(len(X))\n",
    "    moral_preds = np.zeros(len(X))\n",
    "    all_esa = np.zeros(len(X))\n",
    "\n",
    "    #start timer\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        phi_val = esa_features[val_idx]\n",
    "        tau_val = tau_values[val_idx]\n",
    "\n",
    "        model = CatBoostClassifier(**catboost_params)\n",
    "        model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=10)\n",
    "\n",
    "        # Apply ESA-informed decision override\n",
    "        eval_moral, esa_vals, moral_decisions = evaluate_esa_decision_function(model, X_val, phi_val, alpha, tau_val)\n",
    "        preds[val_idx] = model.predict(X_val)\n",
    "        moral_preds[val_idx] = moral_decisions\n",
    "\n",
    "        print(f\"Fold {fold+1}:\", eval_moral)\n",
    "        \n",
    "    #end time\n",
    "    end_time = time.perf_counter()\n",
    "    \n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    print(\"\\n--- Final Evaluation ---\")\n",
    "    print(\"Standard Accuracy:\", accuracy_score(y, preds))\n",
    "    print(\"Moral Accuracy:\", accuracy_score(y, moral_preds))\n",
    "    print(\"Moral Agreement:\", accuracy_score(preds, moral_preds))\n",
    "\n",
    "    \n",
    "metrics = evaluate_classification(y, preds)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb56a24",
   "metadata": {},
   "source": [
    "# Experiment 4 - Logistic Regression on regular Dataset with CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8af477a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Evaluation ---\n",
      "Standard Accuracy: 0.936527423958749\n",
      "Moral Accuracy: 0.7818360394094718\n",
      "Moral Agreement: 0.8371443479328443\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     25473\n",
      "           1       0.97      0.73      0.83      7108\n",
      "\n",
      "    accuracy                           0.94     32581\n",
      "   macro avg       0.95      0.86      0.90     32581\n",
      "weighted avg       0.94      0.94      0.93     32581\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[25340   133]\n",
      " [ 1935  5173]]\n",
      "{'accuracy': 0.936527423958749, 'precision': 0.974934036939314, 'recall': 0.727771525042206, 'f1_score': 0.8334138875463188, 'roc_auc': 0.8612751552114025}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Example dummy ESA weights\n",
    "    #alpha = np.array([0.4, 0.2, 0.3, 0.0, 0.0, 0.1])  # For consequentialism\n",
    "\n",
    "    # Load data (replace this with your actual DataFrame)\n",
    "    df4 = pd.read_csv('credit_risk_dataset.csv')  # Assumes 6 ESA features + CST + loan_status + other inputs\n",
    "\n",
    "    # Initialize LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    # Apply label encoding\n",
    "    df4['person_home_ownership'] = label_encoder.fit_transform(df4['person_home_ownership'])\n",
    "    df4['loan_intent'] = label_encoder.fit_transform(df4['loan_intent'])\n",
    "    df4['loan_grade'] = label_encoder.fit_transform(df4['loan_grade'])\n",
    "    df4['cb_person_default_on_file'] = label_encoder.fit_transform(df4['cb_person_default_on_file'])\n",
    "    \n",
    "    # Extract ESA features and CST\n",
    "    #esa_features = df[['severity_cons','dur_cons','util_cons','prin_up','prin_vi','moral_int']].values\n",
    "    #tau_values = df['CST'].values\n",
    "    y = df['loan_status']\n",
    "    X = df.drop(columns=['loan_status'])\n",
    "\n",
    "    n_splits = 5\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    catboost_params = {\n",
    "        'depth': 7,\n",
    "        'learning_rate': 0.19893301995319765,\n",
    "        'bagging_temperature': 0.7979373495258176,\n",
    "        'l2_leaf_reg': 5,\n",
    "        'loss_function': 'Logloss',\n",
    "        'iterations': 400,\n",
    "        'grow_policy': 'Lossguide',\n",
    "        'eval_metric': 'AUC',\n",
    "        'verbose': False\n",
    "    }\n",
    "\n",
    "    preds = np.zeros(len(X))\n",
    "    moral_preds = np.zeros(len(X))\n",
    "    all_esa = np.zeros(len(X))\n",
    "\n",
    "    #start timer\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        phi_val = esa_features[val_idx]\n",
    "        tau_val = tau_values[val_idx]\n",
    "\n",
    "        model = CatBoostClassifier(**catboost_params)\n",
    "        model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=10)\n",
    "\n",
    "        # Apply ESA-informed decision override\n",
    "        #eval_moral, esa_vals, moral_decisions = evaluate_esa_decision_function(model, X_val, phi_val, alpha, tau_val)\n",
    "        preds[val_idx] = model.predict(X_val)\n",
    "        #moral_preds[val_idx] = moral_decisions\n",
    "\n",
    "        #print(f\"Fold {fold+1}:\", eval_moral)\n",
    "        \n",
    "    #end time\n",
    "    end_time = time.perf_counter()\n",
    "    \n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    print(\"\\n--- Final Evaluation ---\")\n",
    "    print(\"Standard Accuracy:\", accuracy_score(y, preds))\n",
    "    print(\"Moral Accuracy:\", accuracy_score(y, moral_preds))\n",
    "    print(\"Moral Agreement:\", accuracy_score(preds, moral_preds))\n",
    "\n",
    "    \n",
    "metrics = evaluate_classification(y, preds)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81248f68",
   "metadata": {},
   "source": [
    "# Experiment 5 - With Penalized Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc05694c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 ESA Penalized Accuracy: 0.8037440540125825\n",
      "Fold 2 ESA Penalized Accuracy: 0.8031000613873542\n",
      "Fold 3 ESA Penalized Accuracy: 0.8052486187845304\n",
      "Fold 4 ESA Penalized Accuracy: 0.8049416820135052\n",
      "Fold 5 ESA Penalized Accuracy: 0.8032535297728668\n",
      "\n",
      "--- Final Evaluation (Logistic Regression ESA Penalized) ---\n",
      "ESA Penalized Accuracy: 0.8040575795709156\n",
      "Time taken: 0.468315 seconds\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89      5095\n",
      "           1       0.72      0.16      0.26      1421\n",
      "\n",
      "    accuracy                           0.80      6516\n",
      "   macro avg       0.76      0.57      0.58      6516\n",
      "weighted avg       0.79      0.80      0.75      6516\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5003   92]\n",
      " [1190  231]]\n",
      "{'accuracy': 0.8032535297728668, 'precision': 0.7151702786377709, 'recall': 0.1625615763546798, 'f1_score': 0.26490825688073394, 'roc_auc': 0.572252328903542}\n"
     ]
    }
   ],
   "source": [
    " preds_penalized = np.zeros(len(X))\n",
    "\n",
    "#start timer\n",
    "start_time = time.perf_counter()\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    phi_train = esa_features[train_idx]\n",
    "    tau_train = tau_values[train_idx]\n",
    "\n",
    "    moral_penalty = np.array([(tau - esa_score(phi, alpha))**2 for phi, tau in zip(phi_train, tau_train)])\n",
    "    #sample_weights = np.clip(1 + 7 * moral_penalty, 1, 20)\n",
    "    sample_weights = 1 + 7 * moral_penalty\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    preds_penalized[val_idx] = y_val_pred\n",
    "\n",
    "    print(f\"Fold {fold+1} ESA Penalized Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "    \n",
    "    #end time\n",
    "    end_time = time.perf_counter()\n",
    "    \n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"\\n--- Final Evaluation (Logistic Regression ESA Penalized) ---\")\n",
    "print(\"ESA Penalized Accuracy:\", accuracy_score(y, preds_penalized))\n",
    "print(f\"Time taken: {elapsed_time:.6f} seconds\")\n",
    "    \n",
    "\n",
    "metrics = evaluate_classification(y_val, y_val_pred)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e141a3d1",
   "metadata": {},
   "source": [
    "# Override later decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af7ec279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 ESA Override Accuracy: 0.6926499923277581\n",
      "Fold 2 ESA Override Accuracy: 0.6959791282995703\n",
      "Fold 3 ESA Override Accuracy: 0.7004297114794352\n",
      "Fold 4 ESA Override Accuracy: 0.6955187231430325\n",
      "Fold 5 ESA Override Accuracy: 0.6887661141804788\n",
      "\n",
      "--- Final Evaluation (Logistic Regression ESA Override) ---\n",
      "ESA Override Accuracy: 0.6946686719253553\n",
      "Time taken: 0.227110 seconds\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80     25473\n",
      "           1       0.31      0.32      0.31      7108\n",
      "\n",
      "    accuracy                           0.69     32581\n",
      "   macro avg       0.56      0.56      0.56     32581\n",
      "weighted avg       0.70      0.69      0.70     32581\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[20377  5096]\n",
      " [ 4852  2256]]\n",
      "{'accuracy': 0.6946686719253553, 'precision': 0.3068552774755169, 'recall': 0.317388857625211, 'f1_score': 0.31203319502074683, 'roc_auc': 0.5586669487356613}\n"
     ]
    }
   ],
   "source": [
    "alpha = np.array([0.4, 0.2, 0.3, 0.0, 0.0, 0.1])\n",
    "esa_features = df[['severity_cons','dur_cons','util_cons','prin_up','prin_vi','moral_int']].values\n",
    "tau_values = df['CST'].values\n",
    "preds_override = np.zeros(len(X))\n",
    "\n",
    "#start timer\n",
    "start_time = time.perf_counter()\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    phi_val = esa_features[val_idx]\n",
    "    tau_val = tau_values[val_idx]\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # ESA override decision logic\n",
    "    esa_vals = np.array([esa_score(phi, alpha) for phi in phi_val])\n",
    "    moral_decisions = (esa_vals >= tau_val).astype(int)\n",
    "    preds_override[val_idx] = moral_decisions\n",
    "\n",
    "    print(f\"Fold {fold+1} ESA Override Accuracy:\", accuracy_score(y_val, moral_decisions))\n",
    "\n",
    "#end time\n",
    "end_time = time.perf_counter()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"\\n--- Final Evaluation (Logistic Regression ESA Override) ---\")\n",
    "print(\"ESA Override Accuracy:\", accuracy_score(y, preds_override))\n",
    "print(f\"Time taken: {elapsed_time:.6f} seconds\")\n",
    "\n",
    "metrics = evaluate_classification(y, preds_override)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dd060e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
