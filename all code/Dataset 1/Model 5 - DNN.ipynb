{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c45f8263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, confusion_matrix, classification_report, log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddf28928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def esa_score(phi, alpha):\n",
    "    #dot product, weighted sum to calc esa\n",
    "    return np.dot(alpha, phi)\n",
    "\n",
    "#\n",
    "def threshold_crossing_rate(esa_baseline, esa_moral, tau):\n",
    "    crossed = (esa_baseline < tau) & (esa_moral >= tau)\n",
    "    return np.mean(crossed)\n",
    "\n",
    "def moral_win_rate(esa_baseline, esa_moral):\n",
    "    return np.mean(esa_moral > esa_baseline)\n",
    "\n",
    "def esa_difference(esa_baseline, esa_moral):\n",
    "    return np.mean(esa_moral - esa_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d1573b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(y_true, y_pred):\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'f1_score': f1_score(y_true, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_true, y_pred)\n",
    "    }\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b63a3ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.read_csv('credit_risk_dataset - ethics.csv')\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder() \n",
    "\n",
    "# Apply label encoding\n",
    "df6['person_home_ownership'] = label_encoder.fit_transform(df6['person_home_ownership'])\n",
    "df6['loan_intent'] = label_encoder.fit_transform(df6['loan_intent'])\n",
    "df6['loan_grade'] = label_encoder.fit_transform(df6['loan_grade'])\n",
    "df6['cb_person_default_on_file'] = label_encoder.fit_transform(df6['cb_person_default_on_file'])\n",
    "\n",
    "y = df6['loan_status']\n",
    "X = df6.drop(columns=['loan_status', 'CST', 'severity_cons','dur_cons','util_cons','prin_up','prin_vi','moral_int'])\n",
    "esa_features = df6[['severity_cons','dur_cons','util_cons','prin_up','prin_vi','moral_int']].values\n",
    "tau_values = df6['CST'].values\n",
    "alpha = np.array([0.4, 0.2, 0.3, 0.0, 0.0, 0.1])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "dnn_baseline_preds = np.zeros(len(X))\n",
    "dnn_override_preds = np.zeros(len(X))\n",
    "dnn_penalized_preds = np.zeros(len(X))\n",
    "\n",
    "def build_dnn_model(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_dim=input_dim),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05c38a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 874us/step\n",
      "Fold 1 - DNN Baseline:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.95      5095\n",
      "           1       0.92      0.66      0.76      1422\n",
      "\n",
      "    accuracy                           0.91      6517\n",
      "   macro avg       0.91      0.82      0.86      6517\n",
      "weighted avg       0.91      0.91      0.91      6517\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5010   85]\n",
      " [ 489  933]]\n",
      "Fold 1 - DNN ESA Override:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      5095\n",
      "           1       0.31      0.33      0.32      1422\n",
      "\n",
      "    accuracy                           0.69      6517\n",
      "   macro avg       0.56      0.56      0.56      6517\n",
      "weighted avg       0.70      0.69      0.70      6517\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4049 1046]\n",
      " [ 957  465]]\n",
      "204/204 [==============================] - 0s 1ms/step\n",
      "Fold 1 - DNN ESA Penalized:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      5095\n",
      "           1       0.94      0.63      0.75      1422\n",
      "\n",
      "    accuracy                           0.91      6517\n",
      "   macro avg       0.92      0.81      0.85      6517\n",
      "weighted avg       0.91      0.91      0.90      6517\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5037   58]\n",
      " [ 527  895]]\n",
      "204/204 [==============================] - 0s 1ms/step\n",
      "Fold 2 - DNN Baseline:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94      5094\n",
      "           1       0.87      0.68      0.76      1422\n",
      "\n",
      "    accuracy                           0.91      6516\n",
      "   macro avg       0.89      0.83      0.85      6516\n",
      "weighted avg       0.91      0.91      0.90      6516\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4953  141]\n",
      " [ 458  964]]\n",
      "Fold 2 - DNN ESA Override:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      5094\n",
      "           1       0.31      0.33      0.32      1422\n",
      "\n",
      "    accuracy                           0.70      6516\n",
      "   macro avg       0.56      0.56      0.56      6516\n",
      "weighted avg       0.70      0.70      0.70      6516\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4065 1029]\n",
      " [ 952  470]]\n",
      "204/204 [==============================] - 0s 2ms/step\n",
      "Fold 2 - DNN ESA Penalized:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      5094\n",
      "           1       0.93      0.64      0.76      1422\n",
      "\n",
      "    accuracy                           0.91      6516\n",
      "   macro avg       0.92      0.81      0.85      6516\n",
      "weighted avg       0.91      0.91      0.90      6516\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5031   63]\n",
      " [ 518  904]]\n",
      "204/204 [==============================] - 0s 1ms/step\n",
      "Fold 3 - DNN Baseline:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      5094\n",
      "           1       0.93      0.62      0.74      1422\n",
      "\n",
      "    accuracy                           0.91      6516\n",
      "   macro avg       0.92      0.80      0.84      6516\n",
      "weighted avg       0.91      0.91      0.90      6516\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5027   67]\n",
      " [ 542  880]]\n",
      "Fold 3 - DNN ESA Override:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      5094\n",
      "           1       0.31      0.31      0.31      1422\n",
      "\n",
      "    accuracy                           0.70      6516\n",
      "   macro avg       0.56      0.56      0.56      6516\n",
      "weighted avg       0.70      0.70      0.70      6516\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4119  975]\n",
      " [ 977  445]]\n",
      "204/204 [==============================] - 0s 1ms/step\n",
      "Fold 3 - DNN ESA Penalized:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.95      5094\n",
      "           1       0.92      0.67      0.77      1422\n",
      "\n",
      "    accuracy                           0.91      6516\n",
      "   macro avg       0.92      0.82      0.86      6516\n",
      "weighted avg       0.91      0.91      0.91      6516\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5010   84]\n",
      " [ 476  946]]\n",
      "204/204 [==============================] - 0s 1ms/step\n",
      "Fold 4 - DNN Baseline:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      5095\n",
      "           1       0.91      0.65      0.76      1421\n",
      "\n",
      "    accuracy                           0.91      6516\n",
      "   macro avg       0.91      0.81      0.85      6516\n",
      "weighted avg       0.91      0.91      0.90      6516\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5008   87]\n",
      " [ 502  919]]\n",
      "Fold 4 - DNN ESA Override:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      5095\n",
      "           1       0.30      0.30      0.30      1421\n",
      "\n",
      "    accuracy                           0.70      6516\n",
      "   macro avg       0.55      0.55      0.55      6516\n",
      "weighted avg       0.70      0.70      0.70      6516\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4102  993]\n",
      " [ 991  430]]\n",
      "204/204 [==============================] - 0s 1ms/step\n",
      "Fold 4 - DNN ESA Penalized:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      5095\n",
      "           1       0.87      0.66      0.75      1421\n",
      "\n",
      "    accuracy                           0.90      6516\n",
      "   macro avg       0.89      0.81      0.84      6516\n",
      "weighted avg       0.90      0.90      0.90      6516\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4952  143]\n",
      " [ 488  933]]\n",
      "204/204 [==============================] - 0s 1ms/step\n",
      "Fold 5 - DNN Baseline:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      5095\n",
      "           1       0.91      0.65      0.76      1421\n",
      "\n",
      "    accuracy                           0.91      6516\n",
      "   macro avg       0.91      0.82      0.85      6516\n",
      "weighted avg       0.91      0.91      0.90      6516\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5000   95]\n",
      " [ 499  922]]\n",
      "Fold 5 - DNN ESA Override:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      5095\n",
      "           1       0.30      0.31      0.31      1421\n",
      "\n",
      "    accuracy                           0.69      6516\n",
      "   macro avg       0.55      0.55      0.55      6516\n",
      "weighted avg       0.69      0.69      0.69      6516\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4042 1053]\n",
      " [ 975  446]]\n",
      "204/204 [==============================] - 1s 1ms/step\n",
      "Fold 5 - DNN ESA Penalized:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      5095\n",
      "           1       0.91      0.67      0.77      1421\n",
      "\n",
      "    accuracy                           0.91      6516\n",
      "   macro avg       0.91      0.83      0.86      6516\n",
      "weighted avg       0.91      0.91      0.91      6516\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5000   95]\n",
      " [ 464  957]]\n",
      "\n",
      "--- Final Evaluation (DNN Baseline) ---\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94     25473\n",
      "           1       0.91      0.65      0.76      7108\n",
      "\n",
      "    accuracy                           0.91     32581\n",
      "   macro avg       0.91      0.82      0.85     32581\n",
      "weighted avg       0.91      0.91      0.90     32581\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[24998   475]\n",
      " [ 2490  4618]]\n",
      "{'accuracy': 0.9089960406371812, 'precision': 0.9067347339485569, 'recall': 0.6496904895891953, 'f1_score': 0.7569871322022784, 'roc_auc': 0.8155216472599531}\n",
      "\n",
      "--- Final Evaluation (DNN ESA Override) ---\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80     25473\n",
      "           1       0.31      0.32      0.31      7108\n",
      "\n",
      "    accuracy                           0.69     32581\n",
      "   macro avg       0.56      0.56      0.56     32581\n",
      "weighted avg       0.70      0.69      0.70     32581\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[20377  5096]\n",
      " [ 4852  2256]]\n",
      "{'accuracy': 0.6946686719253553, 'precision': 0.3068552774755169, 'recall': 0.317388857625211, 'f1_score': 0.31203319502074683, 'roc_auc': 0.5586669487356613}\n",
      "\n",
      "--- Final Evaluation (DNN ESA Penalized) ---\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94     25473\n",
      "           1       0.91      0.65      0.76      7108\n",
      "\n",
      "    accuracy                           0.91     32581\n",
      "   macro avg       0.91      0.82      0.85     32581\n",
      "weighted avg       0.91      0.91      0.90     32581\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[25030   443]\n",
      " [ 2473  4635]]\n",
      "{'accuracy': 0.9104999846536325, 'precision': 0.912760929499803, 'recall': 0.6520821609454136, 'f1_score': 0.760709010339734, 'roc_auc': 0.8173455989825015}\n",
      "time baseline: 260.96837939999386\n",
      "time override: 0.31636210000215215\n",
      "time penalized: 317.2140990999942\n"
     ]
    }
   ],
   "source": [
    "b_time = 0\n",
    "o_time = 0\n",
    "p_time = 0\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_scaled, y)):\n",
    "    X_train, X_val = X_scaled.iloc[train_idx], X_scaled.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    b_time_s = time.perf_counter()\n",
    "    # -------- Baseline --------\n",
    "    model_baseline = build_dnn_model(X_train.shape[1])\n",
    "    model_baseline.fit(X_train, y_train, epochs=30, batch_size=32, verbose=0,\n",
    "                           validation_data=(X_val, y_val),\n",
    "                           callbacks=[EarlyStopping(patience=5, restore_best_weights=True)])\n",
    "    y_val_pred_baseline = (model_baseline.predict(X_val).flatten() >= 0.5).astype(int)\n",
    "    dnn_baseline_preds[val_idx] = y_val_pred_baseline\n",
    "    print(f\"Fold {fold+1} - DNN Baseline:\")\n",
    "    evaluate_classification(y_val, y_val_pred_baseline)\n",
    "    b_time_e = time.perf_counter()\n",
    "    b_time = b_time + (b_time_e - b_time_s)\n",
    "\n",
    "    o_time_s = time.perf_counter()\n",
    "    # -------- Override --------\n",
    "    phi_val = esa_features[val_idx]\n",
    "    tau_val = tau_values[val_idx]\n",
    "    esa_vals = np.array([esa_score(phi, alpha) for phi in phi_val])\n",
    "    moral_preds = (esa_vals >= tau_val).astype(int)\n",
    "    dnn_override_preds[val_idx] = moral_preds\n",
    "    print(f\"Fold {fold+1} - DNN ESA Override:\")\n",
    "    evaluate_classification(y_val, moral_preds)\n",
    "    o_time_e = time.perf_counter()\n",
    "    o_time = o_time + (o_time_e - o_time_s)\n",
    "\n",
    "    p_time_s = time.perf_counter()\n",
    "    # -------- Penalized --------\n",
    "    phi_train = esa_features[train_idx]\n",
    "    tau_train = tau_values[train_idx]\n",
    "    moral_penalty = np.array([(tau - esa_score(phi, alpha))**2 for phi, tau in zip(phi_train, tau_train)])\n",
    "    sample_weights = np.clip(1 + 5 * moral_penalty, 1, 10)\n",
    "\n",
    "    model_penalized = build_dnn_model(X_train.shape[1])\n",
    "    model_penalized.fit(X_train, y_train, sample_weight=sample_weights, epochs=30, batch_size=32, verbose=0,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        callbacks=[EarlyStopping(patience=5, restore_best_weights=True)])\n",
    "    y_val_pred_penalized = (model_penalized.predict(X_val).flatten() >= 0.5).astype(int)\n",
    "    dnn_penalized_preds[val_idx] = y_val_pred_penalized\n",
    "    print(f\"Fold {fold+1} - DNN ESA Penalized:\")\n",
    "    evaluate_classification(y_val, y_val_pred_penalized)\n",
    "    p_time_e = time.perf_counter()\n",
    "    p_time = p_time + (p_time_e - p_time_s)\n",
    "\n",
    "print(\"\\n--- Final Evaluation (DNN Baseline) ---\")\n",
    "#evaluate_classification(y, dnn_baseline_preds)\n",
    "metrics = evaluate_classification(y, dnn_baseline_preds)\n",
    "print(metrics)\n",
    "\n",
    "print(\"\\n--- Final Evaluation (DNN ESA Override) ---\")\n",
    "#evaluate_classification(y, dnn_override_preds)\n",
    "metrics = evaluate_classification(y, dnn_override_preds)\n",
    "print(metrics)\n",
    "\n",
    "print(\"\\n--- Final Evaluation (DNN ESA Penalized) ---\")\n",
    "#evaluate_classification(y, dnn_penalized_preds)\n",
    "metrics = evaluate_classification(y, dnn_penalized_preds)\n",
    "print(metrics)\n",
    "\n",
    "print(\"time baseline:\", b_time)\n",
    "print(\"time override:\", o_time)\n",
    "print(\"time penalized:\", p_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64cd227",
   "metadata": {},
   "source": [
    "# CVAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "023c1d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import Loss\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "943e97ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def esa_score(phi, alpha):\n",
    "    return np.dot(alpha, phi)\n",
    "\n",
    "def threshold_crossing_rate(esa_baseline, esa_moral, tau):\n",
    "    crossed = (esa_baseline < tau) & (esa_moral >= tau)\n",
    "    return np.mean(crossed)\n",
    "\n",
    "def moral_win_rate(esa_baseline, esa_moral):\n",
    "    return np.mean(esa_moral > esa_baseline)\n",
    "\n",
    "def esa_difference(esa_baseline, esa_moral):\n",
    "    return np.mean(esa_moral - esa_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4ab289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(y_true, y_pred):\n",
    "    return {\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1': f1_score(y_true, y_pred),\n",
    "        'ROC_AUC': roc_auc_score(y_true, y_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dbcb4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVaRLoss(Loss):\n",
    "    def __init__(self, alpha, phi_tensor, tau_tensor, lam=0.8):\n",
    "        #initialize main variables\n",
    "        super().__init__()\n",
    "        self.alpha = K.constant(alpha, dtype='float32')\n",
    "        self.phi_tensor = K.constant(phi_tensor, dtype='float32')\n",
    "        self.tau_tensor = K.constant(tau_tensor, dtype='float32')\n",
    "        self.lam = lam\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        #implement EMS\n",
    "        y_true = K.cast(y_true, dtype='float32')\n",
    "        #regular loss\n",
    "        bce = K.binary_crossentropy(y_true, y_pred)\n",
    "        #esa calc\n",
    "        esa = K.sum(self.phi_tensor * self.alpha, axis=1)\n",
    "        # Penalize low ESA values below CST threshold (penalty = 0 if esa>=cst, positive otherwise)\n",
    "        tail_penalty = K.relu(self.tau_tensor - esa)\n",
    "        return bce + self.lam * tail_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50dc82c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline dnn\n",
    "def build_dnn(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_dim=input_dim),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4908fcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = pd.read_csv('credit_risk_dataset - ethics.csv')\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder() \n",
    "\n",
    "# Apply label encoding\n",
    "df7['person_home_ownership'] = label_encoder.fit_transform(df7['person_home_ownership'])\n",
    "df7['loan_intent'] = label_encoder.fit_transform(df7['loan_intent'])\n",
    "df7['loan_grade'] = label_encoder.fit_transform(df7['loan_grade'])\n",
    "df7['cb_person_default_on_file'] = label_encoder.fit_transform(df7['cb_person_default_on_file'])\n",
    "\n",
    "y = df7['loan_status']\n",
    "X = df7.drop(columns=['loan_status', 'CST', 'severity_cons','dur_cons','util_cons','prin_up','prin_vi','moral_int'])\n",
    "esa_features = df7[['severity_cons','dur_cons','util_cons','prin_up','prin_vi','moral_int']].values\n",
    "phi = df7[['severity_cons','dur_cons','util_cons','prin_up','prin_vi','moral_int']].astype('float32').values\n",
    "\n",
    "tau = df7['CST'].values\n",
    "alpha = np.array([0.4, 0.2, 0.3, 0.0, 0.0, 0.1], dtype='float32')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f8b31fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "dnn_cvar_preds = np.zeros(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15e234a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "204/204 [==============================] - 0s 2ms/step\n",
      "Fold 1 - DNN CVaR Loss:\n",
      "{'Accuracy': 0.7948442534908701, 'Precision': 1.0, 'Recall': 0.05977496483825598, 'F1': 0.11280690112806901, 'ROC_AUC': 0.529887482419128}\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "204/204 [==============================] - 0s 1ms/step\n",
      "Fold 2 - DNN CVaR Loss:\n",
      "{'Accuracy': 0.7920503376304481, 'Precision': 1.0, 'Recall': 0.047116736990154715, 'F1': 0.08999328408327738, 'ROC_AUC': 0.5235583684950773}\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "204/204 [==============================] - 0s 1ms/step\n",
      "Fold 3 - DNN CVaR Loss:\n",
      "{'Accuracy': 0.7879066912216084, 'Precision': 1.0, 'Recall': 0.02812939521800281, 'F1': 0.05471956224350205, 'ROC_AUC': 0.5140646976090014}\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "204/204 [==============================] - 0s 1ms/step\n",
      "Fold 4 - DNN CVaR Loss:\n",
      "{'Accuracy': 0.8040208717004297, 'Precision': 1.0, 'Recall': 0.10133708655876143, 'F1': 0.18402555910543128, 'ROC_AUC': 0.5506685432793808}\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "204/204 [==============================] - 0s 1ms/step\n",
      "Fold 5 - DNN CVaR Loss:\n",
      "{'Accuracy': 0.80463474524248, 'Precision': 1.0, 'Recall': 0.10415200562983815, 'F1': 0.18865519439133205, 'ROC_AUC': 0.5520760028149191}\n",
      "Time taken: 650.198107 seconds\n",
      "{'Accuracy': 0.80463474524248, 'Precision': 1.0, 'Recall': 0.10415200562983815, 'F1': 0.18865519439133205, 'ROC_AUC': 0.5520760028149191}\n"
     ]
    }
   ],
   "source": [
    "#start timer\n",
    "start_time = time.perf_counter()\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_scaled, y)):\n",
    "    X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    phi_train = phi[train_idx]\n",
    "    tau_train = tau[train_idx]\n",
    "\n",
    "    model = build_dnn(X_train.shape[1])\n",
    "    model.compile(optimizer=Adam(0.001), loss=CVaRLoss(alpha, phi_train, tau_train, lam=1.0))\n",
    "    model.fit(X_train, y_train, epochs=30, batch_size=32, verbose=0, callbacks=[EarlyStopping(patience=5, restore_best_weights=True)])\n",
    "    y_val_pred = (model.predict(X_val).flatten() >= 1).astype(int)\n",
    "    dnn_cvar_preds[val_idx] = y_val_pred\n",
    "    print(f\"Fold {fold+1} - DNN CVaR Loss:\")\n",
    "    print(evaluate_classification(y_val, y_val_pred))\n",
    "    \n",
    "end_time = time.perf_counter()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.6f} seconds\")\n",
    "\n",
    "metrics = evaluate_classification(y_val, y_val_pred)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03490ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153c6000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3270051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197d6dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecc1444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c9468c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87632b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a719923",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3037d509",
   "metadata": {},
   "source": [
    "# Adversarial Formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "567e51ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import Loss\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7d84cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def esa_score(phi, alpha):\n",
    "    return np.dot(phi, alpha)\n",
    "\n",
    "def evaluate_classification(y_true, y_pred):\n",
    "    return {\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1': f1_score(y_true, y_pred),\n",
    "        'ROC_AUC': roc_auc_score(y_true, y_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "828611fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversary_loss(esa_true, esa_pred):\n",
    "    return K.mean(K.square(esa_true - esa_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59b631b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_esa_adversary(input_dim):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    x = Dense(32, activation='relu')(inputs)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    esa_output = Dense(1, activation='linear', name='esa_output')(x)\n",
    "    return Model(inputs=inputs, outputs=esa_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12139b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adversarial_model(input_dim):\n",
    "    # Main classifier\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    x = Dense(64, activation='relu')(input_layer)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output_class = Dense(1, activation='sigmoid', name='class_output')(x)\n",
    "\n",
    "    # ESA adversary\n",
    "    x_esa = Dense(16, activation='relu')(x)\n",
    "    output_esa = Dense(1, activation='linear', name='esa_output')(x_esa)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=[output_class, output_esa])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf38f290",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('credit_risk_dataset - ethics.csv')\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder() \n",
    "\n",
    "# Apply label encoding\n",
    "df['person_home_ownership'] = label_encoder.fit_transform(df['person_home_ownership'])\n",
    "df['loan_intent'] = label_encoder.fit_transform(df['loan_intent'])\n",
    "df['loan_grade'] = label_encoder.fit_transform(df['loan_grade'])\n",
    "df['cb_person_default_on_file'] = label_encoder.fit_transform(df['cb_person_default_on_file'])\n",
    "\n",
    "y = df['loan_status']\n",
    "X = df.drop(columns=['loan_status', 'CST', 'severity_cons','dur_cons','util_cons','prin_up','prin_vi','moral_int'])\n",
    "\n",
    "phi = df[['severity_cons','dur_cons','util_cons','prin_up','prin_vi','moral_int']].astype('float32').values\n",
    "alpha = np.array([0.4, 0.2, 0.3, 0.0, 0.0, 0.1], dtype='float32')\n",
    "ESA_target = esa_score(phi, alpha).reshape(-1, 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f75c0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "dnn_adv_preds = np.zeros(len(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a53d7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 786us/step\n",
      "Fold 1 - ESA Adversarial:\n",
      "{'Accuracy': 0.9053245358293693, 'Precision': 0.9197080291970803, 'Recall': 0.620253164556962, 'F1': 0.7408651826963462, 'ROC_AUC': 0.8025701544080198}\n",
      "204/204 [==============================] - 0s 850us/step\n",
      "Fold 2 - ESA Adversarial:\n",
      "{'Accuracy': 0.9165131982811541, 'Precision': 0.9507186858316222, 'Recall': 0.6511954992967651, 'F1': 0.7729549248747913, 'ROC_AUC': 0.8208863244422577}\n",
      "204/204 [==============================] - 0s 896us/step\n",
      "Fold 3 - ESA Adversarial:\n",
      "{'Accuracy': 0.907305095150399, 'Precision': 0.9225206611570248, 'Recall': 0.6279887482419128, 'F1': 0.7472803347280335, 'ROC_AUC': 0.8066327722363863}\n",
      "204/204 [==============================] - 0s 1ms/step\n",
      "Fold 4 - ESA Adversarial:\n",
      "{'Accuracy': 0.9102209944751382, 'Precision': 0.9106090373280943, 'Recall': 0.6523574947220268, 'F1': 0.7601476014760147, 'ROC_AUC': 0.8172484235141046}\n",
      "204/204 [==============================] - 0s 1ms/step\n",
      "Fold 5 - ESA Adversarial:\n",
      "{'Accuracy': 0.9074585635359116, 'Precision': 0.915650406504065, 'Recall': 0.6340605207600282, 'F1': 0.7492723492723493, 'ROC_AUC': 0.8088850199482183}\n",
      "Time taken: 154.607325 seconds\n",
      "{'Accuracy': 0.9074585635359116, 'Precision': 0.915650406504065, 'Recall': 0.6340605207600282, 'F1': 0.7492723492723493, 'ROC_AUC': 0.8088850199482183}\n"
     ]
    }
   ],
   "source": [
    "#start timer\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_scaled, y)):\n",
    "    X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    ESA_train, ESA_val = ESA_target[train_idx], ESA_target[val_idx]\n",
    "\n",
    "    model = build_adversarial_model(X_train.shape[1])\n",
    "    model.compile(optimizer=Adam(0.001),\n",
    "                  loss={'class_output': 'binary_crossentropy', 'esa_output': 'mse'},\n",
    "                  loss_weights={'class_output': 1.0, 'esa_output': 0.5})\n",
    "\n",
    "    model.fit(X_train, {'class_output': y_train, 'esa_output': ESA_train},\n",
    "              epochs=30, batch_size=32, verbose=0,\n",
    "              validation_split=0.1,\n",
    "              callbacks=[EarlyStopping(patience=5, restore_best_weights=True)])\n",
    "\n",
    "    y_val_pred = (model.predict(X_val)[0].flatten() >= 0.5).astype(int)\n",
    "    dnn_adv_preds[val_idx] = y_val_pred\n",
    "    print(f\"Fold {fold+1} - ESA Adversarial:\")\n",
    "    print(evaluate_classification(y_val, y_val_pred))\n",
    "    \n",
    "end_time = time.perf_counter()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.6f} seconds\")\n",
    "\n",
    "metrics = evaluate_classification(y_val, y_val_pred)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c576f3d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
