{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "626513c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, confusion_matrix, classification_report, log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5b5600",
   "metadata": {},
   "source": [
    "# Experiment 1 - Simple Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5c0254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def esa_score(phi, alpha):\n",
    "    return np.dot(alpha, phi)\n",
    "\n",
    "def threshold_crossing_rate(esa_baseline, esa_moral, tau):\n",
    "    crossed = (esa_baseline < tau) & (esa_moral >= tau)\n",
    "    return np.mean(crossed)\n",
    "\n",
    "def moral_win_rate(esa_baseline, esa_moral):\n",
    "    return np.mean(esa_moral > esa_baseline)\n",
    "\n",
    "def esa_difference(esa_baseline, esa_moral):\n",
    "    return np.mean(esa_moral - esa_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e25a491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(y_true, y_pred):\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'f1_score': f1_score(y_true, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_true, y_pred)\n",
    "    }\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    return metrics\n",
    "\n",
    "def evaluate_esa_metrics(esa_baseline, esa_moral, tau):\n",
    "    return {\n",
    "        'esa_diff': esa_difference(esa_baseline, esa_moral),\n",
    "        'tcr': threshold_crossing_rate(esa_baseline, esa_moral, tau),\n",
    "        'moral_win_rate': moral_win_rate(esa_baseline, esa_moral)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "906a5032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Baseline Accuracy: 0.9230769230769231\n",
      "Fold 2 Baseline Accuracy: 0.8717948717948718\n",
      "Fold 3 Baseline Accuracy: 0.8461538461538461\n",
      "Fold 4 Baseline Accuracy: 0.9230769230769231\n",
      "Fold 5 Baseline Accuracy: 0.7948717948717948\n",
      "Fold 6 Baseline Accuracy: 0.8974358974358975\n",
      "Fold 7 Baseline Accuracy: 0.9230769230769231\n",
      "Fold 8 Baseline Accuracy: 0.8461538461538461\n",
      "Fold 9 Baseline Accuracy: 0.9487179487179487\n",
      "Fold 10 Baseline Accuracy: 0.9473684210526315\n",
      "Fold 11 Baseline Accuracy: 0.9473684210526315\n",
      "Fold 12 Baseline Accuracy: 0.868421052631579\n",
      "Fold 13 Baseline Accuracy: 0.8947368421052632\n",
      "Fold 14 Baseline Accuracy: 0.9210526315789473\n",
      "Fold 15 Baseline Accuracy: 0.868421052631579\n",
      "Fold 16 Baseline Accuracy: 0.8157894736842105\n",
      "Fold 17 Baseline Accuracy: 0.9736842105263158\n",
      "Fold 18 Baseline Accuracy: 0.9473684210526315\n",
      "Fold 19 Baseline Accuracy: 0.9210526315789473\n",
      "Fold 20 Baseline Accuracy: 0.868421052631579\n",
      "\n",
      "Logistic Regression Baseline\n",
      "Baseline Accuracy: 0.8972691807542262\n",
      "Time taken: 0.437410 seconds\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85       274\n",
      "           1       0.91      0.94      0.92       495\n",
      "\n",
      "    accuracy                           0.90       769\n",
      "   macro avg       0.89      0.88      0.89       769\n",
      "weighted avg       0.90      0.90      0.90       769\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[227  47]\n",
      " [ 32 463]]\n",
      "{'accuracy': 0.8972691807542262, 'precision': 0.907843137254902, 'recall': 0.9353535353535354, 'f1_score': 0.9213930348258708, 'roc_auc': 0.8819103443191034}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #read orig dataset\n",
    "    df = pd.read_csv('grad admission.csv')\n",
    "    \n",
    "    y = df['accept_status']\n",
    "    X = df.drop(columns=['accept_status'])\n",
    "\n",
    "    n_splits = 20\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    preds = np.zeros(len(X))\n",
    "\n",
    "    #start timer\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        preds[val_idx] = y_val_pred\n",
    "\n",
    "        print(f\"Fold {fold+1} Baseline Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "\n",
    "    #end time\n",
    "    end_time = time.perf_counter()\n",
    "    \n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    print(\"\\nLogistic Regression Baseline\")\n",
    "    print(\"Baseline Accuracy:\", accuracy_score(y, preds))\n",
    "    print(f\"Time taken: {elapsed_time:.6f} seconds\")\n",
    "    \n",
    "    metrics = evaluate_classification(y, preds)\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096c1f5c",
   "metadata": {},
   "source": [
    "# Experiment 2 - Logistic Regression on ESA-augmented Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f85bf15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 ESA-Augmented Accuracy: 0.811042944785276\n",
      "Fold 2 ESA-Augmented Accuracy: 0.7937384898710865\n",
      "Fold 3 ESA-Augmented Accuracy: 0.805402087170043\n",
      "Fold 4 ESA-Augmented Accuracy: 0.8047882136279927\n",
      "Fold 5 ESA-Augmented Accuracy: 0.8004910988336402\n",
      "Fold 6 ESA-Augmented Accuracy: 0.8029465930018416\n",
      "Fold 7 ESA-Augmented Accuracy: 0.8103130755064457\n",
      "Fold 8 ESA-Augmented Accuracy: 0.807243707796194\n",
      "Fold 9 ESA-Augmented Accuracy: 0.809085328422345\n",
      "Fold 10 ESA-Augmented Accuracy: 0.809085328422345\n",
      "Fold 11 ESA-Augmented Accuracy: 0.7961939840392879\n",
      "Fold 12 ESA-Augmented Accuracy: 0.8035604665438919\n",
      "Fold 13 ESA-Augmented Accuracy: 0.8041743400859422\n",
      "Fold 14 ESA-Augmented Accuracy: 0.809085328422345\n",
      "Fold 15 ESA-Augmented Accuracy: 0.8041743400859422\n",
      "Fold 16 ESA-Augmented Accuracy: 0.8011049723756906\n",
      "Fold 17 ESA-Augmented Accuracy: 0.7992633517495396\n",
      "Fold 18 ESA-Augmented Accuracy: 0.8084714548802947\n",
      "Fold 19 ESA-Augmented Accuracy: 0.7986494782074892\n",
      "Fold 20 ESA-Augmented Accuracy: 0.8066298342541437\n",
      "\n",
      "Logistic Regression ESA-Augmented\n",
      "Accuracy: 0.8042724287161229\n",
      "Time taken: 0.837748 seconds\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89     25473\n",
      "           1       0.73      0.16      0.27      7108\n",
      "\n",
      "    accuracy                           0.80     32581\n",
      "   macro avg       0.77      0.57      0.58     32581\n",
      "weighted avg       0.79      0.80      0.75     32581\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[25046   427]\n",
      " [ 5950  1158]]\n",
      "{'accuracy': 0.8042724287161229, 'precision': 0.7305993690851735, 'recall': 0.16291502532357907, 'f1_score': 0.2664212584838376, 'roc_auc': 0.5730760891938039}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #read orig dataset\n",
    "    df2 = pd.read_csv('credit_risk_dataset - ethics.csv')\n",
    "    \n",
    "    # Initialize LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    \n",
    "    # Apply label encoding\n",
    "    df2['person_home_ownership'] = label_encoder.fit_transform(df2['person_home_ownership'])\n",
    "    df2['loan_intent'] = label_encoder.fit_transform(df2['loan_intent'])\n",
    "    df2['loan_grade'] = label_encoder.fit_transform(df2['loan_grade'])\n",
    "    df2['cb_person_default_on_file'] = label_encoder.fit_transform(df2['cb_person_default_on_file'])\n",
    "    \n",
    "    y = df2['loan_status']\n",
    "    X = df2.drop(columns=['loan_status'])\n",
    "\n",
    "    n_splits = 20\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    preds = np.zeros(len(X))\n",
    "\n",
    "    #start timer\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        preds[val_idx] = y_val_pred\n",
    "\n",
    "        print(f\"Fold {fold+1} ESA-Augmented Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "\n",
    "    #end time\n",
    "    end_time = time.perf_counter()\n",
    "    \n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    print(\"\\nLogistic Regression ESA-Augmented\")\n",
    "    print(\"Accuracy:\", accuracy_score(y, preds))\n",
    "    print(f\"Time taken: {elapsed_time:.6f} seconds\")\n",
    "    \n",
    "    metrics = evaluate_classification(y, preds)\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd01bab",
   "metadata": {},
   "source": [
    "# Experiment 3 - Logistic Regression on ESA-augmented Dataset with CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d5ff90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, confusion_matrix, classification_report, log_loss\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb520e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(y_true, y_pred):\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'f1_score': f1_score(y_true, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_true, y_pred)\n",
    "    }\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    return metrics\n",
    "\n",
    "def evaluate_regression(y_true, y_pred):\n",
    "    return {\n",
    "        'mse': mean_squared_error(y_true, y_pred),\n",
    "        'rmse': mean_squared_error(y_true, y_pred, squared=False)\n",
    "    }\n",
    "\n",
    "def evaluate_esa_metrics(esa_baseline, esa_moral, tau):\n",
    "    return {\n",
    "        'esa_diff': esa_difference(esa_baseline, esa_moral),\n",
    "        'tcr': threshold_crossing_rate(esa_baseline, esa_moral, tau),\n",
    "        'moral_win_rate': moral_win_rate(esa_baseline, esa_moral)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3338eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_esa_decision_function(model, X, phi_matrix, alpha, tau_values):\n",
    "    y_proba = model.predict_proba(X)[:, 1]\n",
    "    y_pred = model.predict(X)\n",
    "    esa_scores = np.array([esa_score(phi, alpha) for phi in phi_matrix])\n",
    "    loan_status_moral = (esa_scores >= tau_values).astype(int)\n",
    "\n",
    "    eval_moral = evaluate_classification(y_pred, loan_status_moral)\n",
    "    eval_moral['roc_auc'] = roc_auc_score(y_pred, loan_status_moral)\n",
    "    return eval_moral, esa_scores, loan_status_moral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44fb42f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        65\n",
      "           1       0.58      1.00      0.73        89\n",
      "\n",
      "    accuracy                           0.58       154\n",
      "   macro avg       0.29      0.50      0.37       154\n",
      "weighted avg       0.33      0.58      0.42       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0 65]\n",
      " [ 0 89]]\n",
      "Fold 1: {'accuracy': 0.577922077922078, 'precision': 0.577922077922078, 'recall': 1.0, 'f1_score': 0.7325102880658436, 'roc_auc': 0.5}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        65\n",
      "           1       0.58      1.00      0.73        89\n",
      "\n",
      "    accuracy                           0.58       154\n",
      "   macro avg       0.29      0.50      0.37       154\n",
      "weighted avg       0.33      0.58      0.42       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0 65]\n",
      " [ 0 89]]\n",
      "Fold 2: {'accuracy': 0.577922077922078, 'precision': 0.577922077922078, 'recall': 1.0, 'f1_score': 0.7325102880658436, 'roc_auc': 0.5}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        66\n",
      "           1       0.57      1.00      0.73        88\n",
      "\n",
      "    accuracy                           0.57       154\n",
      "   macro avg       0.29      0.50      0.36       154\n",
      "weighted avg       0.33      0.57      0.42       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0 66]\n",
      " [ 0 88]]\n",
      "Fold 3: {'accuracy': 0.5714285714285714, 'precision': 0.5714285714285714, 'recall': 1.0, 'f1_score': 0.7272727272727273, 'roc_auc': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        65\n",
      "           1       0.58      1.00      0.73        89\n",
      "\n",
      "    accuracy                           0.58       154\n",
      "   macro avg       0.29      0.50      0.37       154\n",
      "weighted avg       0.33      0.58      0.42       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0 65]\n",
      " [ 0 89]]\n",
      "Fold 4: {'accuracy': 0.577922077922078, 'precision': 0.577922077922078, 'recall': 1.0, 'f1_score': 0.7325102880658436, 'roc_auc': 0.5}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        64\n",
      "           1       0.58      1.00      0.74        89\n",
      "\n",
      "    accuracy                           0.58       153\n",
      "   macro avg       0.29      0.50      0.37       153\n",
      "weighted avg       0.34      0.58      0.43       153\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0 64]\n",
      " [ 0 89]]\n",
      "Fold 5: {'accuracy': 0.5816993464052288, 'precision': 0.5816993464052288, 'recall': 1.0, 'f1_score': 0.7355371900826446, 'roc_auc': 0.5}\n",
      "\n",
      "--- Final Evaluation ---\n",
      "Standard Accuracy: 0.9986996098829649\n",
      "Moral Accuracy: 0.5786736020806242\n",
      "Moral Agreement: 0.577373211963589\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       324\n",
      "           1       1.00      1.00      1.00       445\n",
      "\n",
      "    accuracy                           1.00       769\n",
      "   macro avg       1.00      1.00      1.00       769\n",
      "weighted avg       1.00      1.00      1.00       769\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[324   0]\n",
      " [  1 444]]\n",
      "{'accuracy': 0.9986996098829649, 'precision': 1.0, 'recall': 0.9977528089887641, 'f1_score': 0.998875140607424, 'roc_auc': 0.9988764044943821}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Example dummy ESA weights\n",
    "    alpha = np.array([0.4, 0.2, 0.3, 0.0, 0.0, 0.1])  # For consequentialism\n",
    "\n",
    "    # Load data (replace this with your actual DataFrame)\n",
    "    df = pd.read_csv('grad admission - ethics.csv')  # Assumes 6 ESA features + CST + loan_status + other inputs\n",
    "    \n",
    "    # Extract ESA features and CST\n",
    "    esa_features = df[['severity_cons','dur_cons','util_cons','prin_up','prin_vi','moral_int']].values\n",
    "    tau_values = df['CST'].values\n",
    "    y = df['accept_status_moral']\n",
    "    X = df.drop(columns=['accept_status', 'ESA', 'CST', 'severity_cons','dur_cons','util_cons','prin_up','prin_vi','moral_int', 'accept_status_moral'])\n",
    "\n",
    "    n_splits = 5\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    catboost_params = {\n",
    "        'depth': 7,\n",
    "        'learning_rate': 0.19893301995319765,\n",
    "        'bagging_temperature': 0.7979373495258176,\n",
    "        'l2_leaf_reg': 5,\n",
    "        'loss_function': 'Logloss',\n",
    "        'iterations': 400,\n",
    "        'grow_policy': 'Lossguide',\n",
    "        'eval_metric': 'AUC',\n",
    "        'verbose': False\n",
    "    }\n",
    "\n",
    "    preds = np.zeros(len(X))\n",
    "    moral_preds = np.zeros(len(X))\n",
    "    all_esa = np.zeros(len(X))\n",
    "\n",
    "    #start timer\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        phi_val = esa_features[val_idx]\n",
    "        tau_val = tau_values[val_idx]\n",
    "\n",
    "        model = CatBoostClassifier(**catboost_params)\n",
    "        model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=10)\n",
    "\n",
    "        # Apply ESA-informed decision override\n",
    "        eval_moral, esa_vals, moral_decisions = evaluate_esa_decision_function(model, X_val, phi_val, alpha, tau_val)\n",
    "        preds[val_idx] = model.predict(X_val)\n",
    "        moral_preds[val_idx] = moral_decisions\n",
    "\n",
    "        print(f\"Fold {fold+1}:\", eval_moral)\n",
    "        \n",
    "    #end time\n",
    "    end_time = time.perf_counter()\n",
    "    \n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    print(\"\\n--- Final Evaluation ---\")\n",
    "    print(\"Standard Accuracy:\", accuracy_score(y, preds))\n",
    "    print(\"Moral Accuracy:\", accuracy_score(y, moral_preds))\n",
    "    print(\"Moral Agreement:\", accuracy_score(preds, moral_preds))\n",
    "\n",
    "    \n",
    "metrics = evaluate_classification(y, preds)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad10d41e",
   "metadata": {},
   "source": [
    "# Experiment 4 - Logistic Regression on regular Dataset with CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "338755f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Evaluation ---\n",
      "Standard Accuracy: 0.936527423958749\n",
      "Moral Accuracy: 0.7818360394094718\n",
      "Moral Agreement: 0.8371443479328443\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     25473\n",
      "           1       0.97      0.73      0.83      7108\n",
      "\n",
      "    accuracy                           0.94     32581\n",
      "   macro avg       0.95      0.86      0.90     32581\n",
      "weighted avg       0.94      0.94      0.93     32581\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[25340   133]\n",
      " [ 1935  5173]]\n",
      "{'accuracy': 0.936527423958749, 'precision': 0.974934036939314, 'recall': 0.727771525042206, 'f1_score': 0.8334138875463188, 'roc_auc': 0.8612751552114025}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Example dummy ESA weights\n",
    "    #alpha = np.array([0.4, 0.2, 0.3, 0.0, 0.0, 0.1])  # For consequentialism\n",
    "\n",
    "    # Load data (replace this with your actual DataFrame)\n",
    "    df4 = pd.read_csv('credit_risk_dataset.csv')  # Assumes 6 ESA features + CST + loan_status + other inputs\n",
    "\n",
    "    # Initialize LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    # Apply label encoding\n",
    "    df4['person_home_ownership'] = label_encoder.fit_transform(df4['person_home_ownership'])\n",
    "    df4['loan_intent'] = label_encoder.fit_transform(df4['loan_intent'])\n",
    "    df4['loan_grade'] = label_encoder.fit_transform(df4['loan_grade'])\n",
    "    df4['cb_person_default_on_file'] = label_encoder.fit_transform(df4['cb_person_default_on_file'])\n",
    "    \n",
    "    # Extract ESA features and CST\n",
    "    #esa_features = df[['severity_cons','dur_cons','util_cons','prin_up','prin_vi','moral_int']].values\n",
    "    #tau_values = df['CST'].values\n",
    "    y = df['loan_status']\n",
    "    X = df.drop(columns=['loan_status'])\n",
    "\n",
    "    n_splits = 5\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    catboost_params = {\n",
    "        'depth': 7,\n",
    "        'learning_rate': 0.19893301995319765,\n",
    "        'bagging_temperature': 0.7979373495258176,\n",
    "        'l2_leaf_reg': 5,\n",
    "        'loss_function': 'Logloss',\n",
    "        'iterations': 400,\n",
    "        'grow_policy': 'Lossguide',\n",
    "        'eval_metric': 'AUC',\n",
    "        'verbose': False\n",
    "    }\n",
    "\n",
    "    preds = np.zeros(len(X))\n",
    "    moral_preds = np.zeros(len(X))\n",
    "    all_esa = np.zeros(len(X))\n",
    "\n",
    "    #start timer\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        phi_val = esa_features[val_idx]\n",
    "        tau_val = tau_values[val_idx]\n",
    "\n",
    "        model = CatBoostClassifier(**catboost_params)\n",
    "        model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=10)\n",
    "\n",
    "        # Apply ESA-informed decision override\n",
    "        #eval_moral, esa_vals, moral_decisions = evaluate_esa_decision_function(model, X_val, phi_val, alpha, tau_val)\n",
    "        preds[val_idx] = model.predict(X_val)\n",
    "        #moral_preds[val_idx] = moral_decisions\n",
    "\n",
    "        #print(f\"Fold {fold+1}:\", eval_moral)\n",
    "        \n",
    "    #end time\n",
    "    end_time = time.perf_counter()\n",
    "    \n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    print(\"\\n--- Final Evaluation ---\")\n",
    "    print(\"Standard Accuracy:\", accuracy_score(y, preds))\n",
    "    print(\"Moral Accuracy:\", accuracy_score(y, moral_preds))\n",
    "    print(\"Moral Agreement:\", accuracy_score(preds, moral_preds))\n",
    "\n",
    "    \n",
    "metrics = evaluate_classification(y, preds)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b02edc",
   "metadata": {},
   "source": [
    "# Experiment 5 - With Penalized Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "282dae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(y_true, y_pred):\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'f1_score': f1_score(y_true, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_true, y_pred)\n",
    "    }\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    return metrics\n",
    "\n",
    "def evaluate_regression(y_true, y_pred):\n",
    "    return {\n",
    "        'mse': mean_squared_error(y_true, y_pred),\n",
    "        'rmse': mean_squared_error(y_true, y_pred, squared=False)\n",
    "    }\n",
    "\n",
    "def evaluate_esa_metrics(esa_baseline, esa_moral, tau):\n",
    "    return {\n",
    "        'esa_diff': esa_difference(esa_baseline, esa_moral),\n",
    "        'tcr': threshold_crossing_rate(esa_baseline, esa_moral, tau),\n",
    "        'moral_win_rate': moral_win_rate(esa_baseline, esa_moral)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c89814c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_esa_decision_function(model, X, phi_matrix, alpha, tau_values):\n",
    "    y_proba = model.predict_proba(X)[:, 1]\n",
    "    y_pred = model.predict(X)\n",
    "    esa_scores = np.array([esa_score(phi, alpha) for phi in phi_matrix])\n",
    "    loan_status_moral = (esa_scores >= tau_values).astype(int)\n",
    "\n",
    "    eval_moral = evaluate_classification(y_pred, loan_status_moral)\n",
    "    eval_moral['roc_auc'] = roc_auc_score(y_pred, loan_status_moral)\n",
    "    return eval_moral, esa_scores, loan_status_moral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53f4808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (replace this with your actual DataFrame)\n",
    "df = pd.read_csv('grad admission - ethics.csv')  # Assumes 6 ESA features + CST + admission_status + other inputs\n",
    "\n",
    "# Extract ESA features and CST\n",
    "esa_features = df[['severity_cons','dur_cons','util_cons','prin_up','prin_vi','moral_int']].values\n",
    "tau_values = df['CST'].values\n",
    "y = df['accept_status_moral']\n",
    "X = df.drop(columns=['accept_status', 'ESA', 'CST', 'severity_cons','dur_cons','util_cons','prin_up','prin_vi','moral_int', 'accept_status_moral'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05b8233a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 ESA Penalized Accuracy: 1.0\n",
      "Fold 2 ESA Penalized Accuracy: 1.0\n",
      "Fold 3 ESA Penalized Accuracy: 1.0\n",
      "Fold 4 ESA Penalized Accuracy: 1.0\n",
      "Fold 5 ESA Penalized Accuracy: 1.0\n",
      "\n",
      "--- Final Evaluation (Logistic Regression ESA Penalized) ---\n",
      "ESA Penalized Accuracy: 1.0\n",
      "Time taken: 0.161866 seconds\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       324\n",
      "           1       1.00      1.00      1.00       445\n",
      "\n",
      "    accuracy                           1.00       769\n",
      "   macro avg       1.00      1.00      1.00       769\n",
      "weighted avg       1.00      1.00      1.00       769\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[324   0]\n",
      " [  0 445]]\n",
      "{'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'roc_auc': 1.0}\n"
     ]
    }
   ],
   "source": [
    " preds_penalized = np.zeros(len(X))\n",
    "\n",
    "#start timer\n",
    "start_time = time.perf_counter()\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    phi_train = esa_features[train_idx]\n",
    "    tau_train = tau_values[train_idx]\n",
    "\n",
    "    moral_penalty = np.array([(tau - esa_score(phi, alpha))**2 for phi, tau in zip(phi_train, tau_train)])\n",
    "    sample_weights = np.clip(1 + 5 * moral_penalty, 1, 10)\n",
    "\n",
    "    model2 = LogisticRegression(max_iter=1000)\n",
    "    model2.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "    y_val_pred = model2.predict(X_val)\n",
    "    preds_penalized[val_idx] = y_val_pred\n",
    "\n",
    "    print(f\"Fold {fold+1} ESA Penalized Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "    \n",
    "    #end time\n",
    "    end_time = time.perf_counter()\n",
    "    \n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"\\n--- Final Evaluation (Logistic Regression ESA Penalized) ---\")\n",
    "print(\"ESA Penalized Accuracy:\", accuracy_score(y, preds_penalized))\n",
    "print(f\"Time taken: {elapsed_time:.6f} seconds\")\n",
    "    \n",
    "\n",
    "metrics = evaluate_classification(y, preds_penalized)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b75f85c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      gre_score  toefl_score  uni_rating  sop  lor  cgpa  research  \\\n",
       "0          337          118           4  4.5  4.5  9.65         1   \n",
       "1          324          107           4  4.0  4.5  8.87         1   \n",
       "2          316          104           3  3.0  3.5  8.00         1   \n",
       "3          322          110           3  3.5  2.5  8.67         1   \n",
       "4          314          103           2  2.0  3.0  8.21         0   \n",
       "..         ...          ...         ...  ...  ...   ...       ...   \n",
       "764        302          110           3  4.0  4.5  8.50         0   \n",
       "765        297           99           4  3.0  3.5  7.81         0   \n",
       "766        298          101           4  2.5  4.5  7.69         1   \n",
       "767        300           95           2  3.0  1.5  8.22         1   \n",
       "768        301           99           3  2.5  2.0  8.45         1   \n",
       "\n",
       "     accept_status  severity_cons  dur_cons  util_cons   prin_up  prin_vi  \\\n",
       "0                1       0.956485   0.77200   0.979837  0.939044        0   \n",
       "1                1       0.154741   0.70960   0.910536  0.884985        0   \n",
       "2                1       0.256471   0.48000   0.865359  0.757353        0   \n",
       "3                1       0.178900   0.52020   0.910242  0.753515        0   \n",
       "4                1       0.241782   0.19704   0.867621  0.686132        0   \n",
       "..             ...            ...       ...        ...       ...      ...   \n",
       "764              1       0.245000   0.30600   0.442484  0.859559        0   \n",
       "765              0       0.317774   0.37488   0.413255  0.738632        1   \n",
       "766              0       0.325994   0.61520   0.414523  0.761368        1   \n",
       "767              1       0.274706   0.32880   0.416003  0.651088        0   \n",
       "768              1       0.251926   0.50700   0.425882  0.657574        0   \n",
       "\n",
       "     moral_int       ESA       CST  accept_status_moral  \n",
       "0     0.933333  0.872009  0.214371                    1  \n",
       "1     0.900000  0.616099  0.222791                    1  \n",
       "2     0.766667  0.549076  0.201991                    1  \n",
       "3     0.733333  0.548106  0.207246                    1  \n",
       "4     0.333333  0.429942  0.197700                    1  \n",
       "..         ...       ...       ...                  ...  \n",
       "764   0.566667 -0.379027  0.188342                    0  \n",
       "765   0.433333 -0.308666  0.179927                    0  \n",
       "766   0.800000 -0.406434  0.175775                    0  \n",
       "767   0.633333 -0.374623  0.173113                    0  \n",
       "768   0.633333 -0.419222  0.175165                    0  \n",
       "\n",
       "[769 rows x 17 columns]>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0ead71",
   "metadata": {},
   "source": [
    "# Override later decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb717cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 ESA Override Accuracy: 0.577922077922078\n",
      "Fold 2 ESA Override Accuracy: 0.577922077922078\n",
      "Fold 3 ESA Override Accuracy: 0.577922077922078\n",
      "Fold 4 ESA Override Accuracy: 0.577922077922078\n",
      "Fold 5 ESA Override Accuracy: 0.5816993464052288\n",
      "\n",
      "--- Final Evaluation (Logistic Regression ESA Override) ---\n",
      "ESA Override Accuracy: 0.5786736020806242\n",
      "Time taken: 0.140122 seconds\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       324\n",
      "           1       0.58      1.00      0.73       445\n",
      "\n",
      "    accuracy                           0.58       769\n",
      "   macro avg       0.29      0.50      0.37       769\n",
      "weighted avg       0.33      0.58      0.42       769\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0 324]\n",
      " [  0 445]]\n",
      "{'accuracy': 0.5786736020806242, 'precision': 0.5786736020806242, 'recall': 1.0, 'f1_score': 0.7331136738056013, 'roc_auc': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "alpha = np.array([0.4, 0.2, 0.3, 0.0, 0.0, 0.1])\n",
    "esa_features = df[['severity_cons','dur_cons','util_cons','prin_up','prin_vi','moral_int']].values\n",
    "tau_values = df['CST'].values\n",
    "preds_override = np.zeros(len(X))\n",
    "\n",
    "#start timer\n",
    "start_time = time.perf_counter()\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    phi_val = esa_features[val_idx]\n",
    "    tau_val = tau_values[val_idx]\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # ESA override decision logic\n",
    "    esa_vals = np.array([esa_score(phi, alpha) for phi in phi_val])\n",
    "    moral_decisions = (esa_vals >= tau_val).astype(int)\n",
    "    preds_override[val_idx] = moral_decisions\n",
    "\n",
    "    print(f\"Fold {fold+1} ESA Override Accuracy:\", accuracy_score(y_val, moral_decisions))\n",
    "\n",
    "#end time\n",
    "end_time = time.perf_counter()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"\\n--- Final Evaluation (Logistic Regression ESA Override) ---\")\n",
    "print(\"ESA Override Accuracy:\", accuracy_score(y, preds_override))\n",
    "print(f\"Time taken: {elapsed_time:.6f} seconds\")\n",
    "\n",
    "metrics = evaluate_classification(y, preds_override)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e12cb6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
