{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c8d7fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, confusion_matrix, classification_report, log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f6da9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def esa_score(phi, alpha):\n",
    "    return np.dot(alpha, phi)\n",
    "\n",
    "def threshold_crossing_rate(esa_baseline, esa_moral, tau):\n",
    "    crossed = (esa_baseline < tau) & (esa_moral >= tau)\n",
    "    return np.mean(crossed)\n",
    "\n",
    "def moral_win_rate(esa_baseline, esa_moral):\n",
    "    return np.mean(esa_moral > esa_baseline)\n",
    "\n",
    "def esa_difference(esa_baseline, esa_moral):\n",
    "    return np.mean(esa_moral - esa_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f35ab5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(y_true, y_pred):\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'f1_score': f1_score(y_true, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_true, y_pred)\n",
    "    }\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc395389",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('grad admission - ethics.csv')\n",
    "    \n",
    "y = df['accept_status_moral']\n",
    "X = df.drop(columns=['accept_status', 'ESA', 'CST', 'severity_cons','dur_cons','util_cons','prin_up','prin_vi','moral_int', 'accept_status_moral'])\n",
    "\n",
    "esa_features = df[['severity_cons','dur_cons','util_cons','prin_up','prin_vi','moral_int']].values\n",
    "tau_values = df['CST'].values\n",
    "alpha = np.array([0.4, 0.2, 0.3, 0.0, 0.0, 0.1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cce41177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Naive Bayes Baseline:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90        65\n",
      "           1       0.95      0.90      0.92        89\n",
      "\n",
      "    accuracy                           0.92       154\n",
      "   macro avg       0.91      0.92      0.91       154\n",
      "weighted avg       0.92      0.92      0.92       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[61  4]\n",
      " [ 9 80]]\n",
      "Fold 1 - Naive Bayes ESA Override:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        65\n",
      "           1       0.58      1.00      0.73        89\n",
      "\n",
      "    accuracy                           0.58       154\n",
      "   macro avg       0.29      0.50      0.37       154\n",
      "weighted avg       0.33      0.58      0.42       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0 65]\n",
      " [ 0 89]]\n",
      "Fold 1 - Naive Bayes ESA Penalized:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90        65\n",
      "           1       0.95      0.90      0.92        89\n",
      "\n",
      "    accuracy                           0.92       154\n",
      "   macro avg       0.91      0.92      0.91       154\n",
      "weighted avg       0.92      0.92      0.92       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[61  4]\n",
      " [ 9 80]]\n",
      "Fold 2 - Naive Bayes Baseline:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86        65\n",
      "           1       0.93      0.84      0.88        89\n",
      "\n",
      "    accuracy                           0.87       154\n",
      "   macro avg       0.87      0.88      0.87       154\n",
      "weighted avg       0.88      0.87      0.87       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[59  6]\n",
      " [14 75]]\n",
      "Fold 2 - Naive Bayes ESA Override:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        65\n",
      "           1       0.58      1.00      0.73        89\n",
      "\n",
      "    accuracy                           0.58       154\n",
      "   macro avg       0.29      0.50      0.37       154\n",
      "weighted avg       0.33      0.58      0.42       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0 65]\n",
      " [ 0 89]]\n",
      "Fold 2 - Naive Bayes ESA Penalized:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85        65\n",
      "           1       0.93      0.83      0.88        89\n",
      "\n",
      "    accuracy                           0.86       154\n",
      "   macro avg       0.86      0.87      0.86       154\n",
      "weighted avg       0.87      0.86      0.86       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[59  6]\n",
      " [15 74]]\n",
      "Fold 3 - Naive Bayes Baseline:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93        65\n",
      "           1       0.97      0.93      0.95        89\n",
      "\n",
      "    accuracy                           0.94       154\n",
      "   macro avg       0.94      0.94      0.94       154\n",
      "weighted avg       0.94      0.94      0.94       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[62  3]\n",
      " [ 6 83]]\n",
      "Fold 3 - Naive Bayes ESA Override:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        65\n",
      "           1       0.58      1.00      0.73        89\n",
      "\n",
      "    accuracy                           0.58       154\n",
      "   macro avg       0.29      0.50      0.37       154\n",
      "weighted avg       0.33      0.58      0.42       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0 65]\n",
      " [ 0 89]]\n",
      "Fold 3 - Naive Bayes ESA Penalized:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93        65\n",
      "           1       0.96      0.92      0.94        89\n",
      "\n",
      "    accuracy                           0.94       154\n",
      "   macro avg       0.93      0.94      0.93       154\n",
      "weighted avg       0.94      0.94      0.94       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[62  3]\n",
      " [ 7 82]]\n",
      "Fold 4 - Naive Bayes Baseline:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90        65\n",
      "           1       0.96      0.88      0.92        89\n",
      "\n",
      "    accuracy                           0.91       154\n",
      "   macro avg       0.91      0.92      0.91       154\n",
      "weighted avg       0.91      0.91      0.91       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[62  3]\n",
      " [11 78]]\n",
      "Fold 4 - Naive Bayes ESA Override:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        65\n",
      "           1       0.58      1.00      0.73        89\n",
      "\n",
      "    accuracy                           0.58       154\n",
      "   macro avg       0.29      0.50      0.37       154\n",
      "weighted avg       0.33      0.58      0.42       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0 65]\n",
      " [ 0 89]]\n",
      "Fold 4 - Naive Bayes ESA Penalized:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89        65\n",
      "           1       0.96      0.87      0.91        89\n",
      "\n",
      "    accuracy                           0.90       154\n",
      "   macro avg       0.90      0.91      0.90       154\n",
      "weighted avg       0.91      0.90      0.90       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[62  3]\n",
      " [12 77]]\n",
      "Fold 5 - Naive Bayes Baseline:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89        64\n",
      "           1       0.96      0.87      0.91        89\n",
      "\n",
      "    accuracy                           0.90       153\n",
      "   macro avg       0.90      0.91      0.90       153\n",
      "weighted avg       0.91      0.90      0.90       153\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[61  3]\n",
      " [12 77]]\n",
      "Fold 5 - Naive Bayes ESA Override:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        64\n",
      "           1       0.58      1.00      0.74        89\n",
      "\n",
      "    accuracy                           0.58       153\n",
      "   macro avg       0.29      0.50      0.37       153\n",
      "weighted avg       0.34      0.58      0.43       153\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0 64]\n",
      " [ 0 89]]\n",
      "Fold 5 - Naive Bayes ESA Penalized:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89        64\n",
      "           1       0.96      0.87      0.91        89\n",
      "\n",
      "    accuracy                           0.90       153\n",
      "   macro avg       0.90      0.91      0.90       153\n",
      "weighted avg       0.91      0.90      0.90       153\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[61  3]\n",
      " [12 77]]\n",
      "\n",
      "--- Final Evaluation (Naive Bayes Baseline) ---\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.90       324\n",
      "           1       0.95      0.88      0.92       445\n",
      "\n",
      "    accuracy                           0.91       769\n",
      "   macro avg       0.90      0.91      0.91       769\n",
      "weighted avg       0.91      0.91      0.91       769\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[305  19]\n",
      " [ 52 393]]\n",
      "Accuracy: 0.9076723016905072\n",
      "\n",
      "--- Final Evaluation (Naive Bayes ESA Override) ---\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       324\n",
      "           1       0.58      1.00      0.73       445\n",
      "\n",
      "    accuracy                           0.58       769\n",
      "   macro avg       0.29      0.50      0.37       769\n",
      "weighted avg       0.33      0.58      0.42       769\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0 324]\n",
      " [  0 445]]\n",
      "Accuracy: 0.5786736020806242\n",
      "\n",
      "--- Final Evaluation (Naive Bayes ESA Penalized) ---\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89       324\n",
      "           1       0.95      0.88      0.91       445\n",
      "\n",
      "    accuracy                           0.90       769\n",
      "   macro avg       0.90      0.91      0.90       769\n",
      "weighted avg       0.91      0.90      0.90       769\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[305  19]\n",
      " [ 55 390]]\n",
      "Accuracy: 0.9037711313394018\n",
      "time baseline: 0.03987020067870617\n",
      "time override: 0.02882679831236601\n",
      "time penalized: 0.03992200084030628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "nb_baseline_preds = np.zeros(len(X))\n",
    "nb_override_preds = np.zeros(len(X))\n",
    "nb_penalized_preds = np.zeros(len(X))\n",
    "\n",
    "b_time = 0\n",
    "o_time = 0\n",
    "p_time = 0\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_scaled, y)):\n",
    "    X_train, X_val = X_scaled.iloc[train_idx], X_scaled.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    b_time_s = time.perf_counter()\n",
    "    # -------- Baseline --------\n",
    "    model_baseline = GaussianNB()\n",
    "    model_baseline.fit(X_train, y_train)\n",
    "    y_val_pred_baseline = model_baseline.predict(X_val)\n",
    "    nb_baseline_preds[val_idx] = y_val_pred_baseline\n",
    "    print(f\"Fold {fold+1} - Naive Bayes Baseline:\")\n",
    "    evaluate_classification(y_val, y_val_pred_baseline)\n",
    "    b_time_e = time.perf_counter()\n",
    "    b_time = b_time + (b_time_e - b_time_s)\n",
    "    \n",
    "    o_time_s = time.perf_counter()\n",
    "    # -------- Override --------\n",
    "    phi_val = esa_features[val_idx]\n",
    "    tau_val = tau_values[val_idx]\n",
    "    esa_vals = np.array([esa_score(phi, alpha) for phi in phi_val])\n",
    "    moral_preds = (esa_vals >= tau_val).astype(int)\n",
    "    nb_override_preds[val_idx] = moral_preds\n",
    "    print(f\"Fold {fold+1} - Naive Bayes ESA Override:\")\n",
    "    evaluate_classification(y_val, moral_preds)\n",
    "    o_time_e = time.perf_counter()\n",
    "    o_time = o_time + (o_time_e - o_time_s)\n",
    "\n",
    "    p_time_s = time.perf_counter()\n",
    "    # -------- Penalized -------- (reweighting the train set)\n",
    "    phi_train = esa_features[train_idx]\n",
    "    tau_train = tau_values[train_idx]\n",
    "    moral_penalty = np.array([(tau - esa_score(phi, alpha))**2 for phi, tau in zip(phi_train, tau_train)])\n",
    "    sample_weights = np.clip(1 + 7 * moral_penalty, 1, 10)\n",
    "    \n",
    "    model_penalized = GaussianNB()\n",
    "    model_penalized.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "    y_val_pred_penalized = model_penalized.predict(X_val)\n",
    "    nb_penalized_preds[val_idx] = y_val_pred_penalized\n",
    "    print(f\"Fold {fold+1} - Naive Bayes ESA Penalized:\")\n",
    "    evaluate_classification(y_val, y_val_pred_penalized)\n",
    "    p_time_e = time.perf_counter()\n",
    "    p_time = p_time + (p_time_e - p_time_s)\n",
    "    \n",
    "print(\"\\n--- Final Evaluation (Naive Bayes Baseline) ---\")\n",
    "evaluate_classification(y, nb_baseline_preds)\n",
    "print(\"Accuracy:\", accuracy_score(y, nb_baseline_preds))\n",
    "\n",
    "print(\"\\n--- Final Evaluation (Naive Bayes ESA Override) ---\")\n",
    "evaluate_classification(y, nb_override_preds)\n",
    "print(\"Accuracy:\", accuracy_score(y, nb_override_preds))\n",
    "\n",
    "print(\"\\n--- Final Evaluation (Naive Bayes ESA Penalized) ---\")\n",
    "evaluate_classification(y, nb_penalized_preds)\n",
    "print(\"Accuracy:\", accuracy_score(y, nb_penalized_preds))\n",
    "\n",
    "print(\"time baseline:\", b_time)\n",
    "print(\"time override:\", o_time)\n",
    "print(\"time penalized:\", p_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb83e245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "530a634e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89       324\n",
      "           1       0.95      0.88      0.91       445\n",
      "\n",
      "    accuracy                           0.90       769\n",
      "   macro avg       0.90      0.91      0.90       769\n",
      "weighted avg       0.91      0.90      0.90       769\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[305  19]\n",
      " [ 55 390]]\n",
      "{'accuracy': 0.9037711313394018, 'precision': 0.9535452322738386, 'recall': 0.8764044943820225, 'f1_score': 0.9133489461358314, 'roc_auc': 0.9088812595366902}\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate_classification(y, nb_penalized_preds)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c1ff6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       324\n",
      "           1       0.58      1.00      0.73       445\n",
      "\n",
      "    accuracy                           0.58       769\n",
      "   macro avg       0.29      0.50      0.37       769\n",
      "weighted avg       0.33      0.58      0.42       769\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0 324]\n",
      " [  0 445]]\n",
      "{'accuracy': 0.5786736020806242, 'precision': 0.5786736020806242, 'recall': 1.0, 'f1_score': 0.7331136738056013, 'roc_auc': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate_classification(y, nb_override_preds)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "450973c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.90       324\n",
      "           1       0.95      0.88      0.92       445\n",
      "\n",
      "    accuracy                           0.91       769\n",
      "   macro avg       0.90      0.91      0.91       769\n",
      "weighted avg       0.91      0.91      0.91       769\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[305  19]\n",
      " [ 52 393]]\n",
      "{'accuracy': 0.9076723016905072, 'precision': 0.9538834951456311, 'recall': 0.8831460674157303, 'f1_score': 0.9171528588098017, 'roc_auc': 0.9122520460535442}\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate_classification(y, nb_baseline_preds)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723c9a69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
