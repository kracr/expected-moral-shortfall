{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72857cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, confusion_matrix, classification_report, log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af35f7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def esa_score(phi, alpha):\n",
    "    return np.dot(alpha, phi)\n",
    "\n",
    "def threshold_crossing_rate(esa_baseline, esa_moral, tau):\n",
    "    crossed = (esa_baseline < tau) & (esa_moral >= tau)\n",
    "    return np.mean(crossed)\n",
    "\n",
    "def moral_win_rate(esa_baseline, esa_moral):\n",
    "    return np.mean(esa_moral > esa_baseline)\n",
    "\n",
    "def esa_difference(esa_baseline, esa_moral):\n",
    "    return np.mean(esa_moral - esa_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f8bbe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(y_true, y_pred):\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'f1_score': f1_score(y_true, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_true, y_pred)\n",
    "    }\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ce809a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('grad admission - ethics.csv')\n",
    "    \n",
    "y = df['accept_status_moral']\n",
    "X = df.drop(columns=['accept_status', 'ESA', 'CST', 'severity_cons','dur_cons','util_cons','prin_up','prin_vi','moral_int', 'accept_status_moral'])\n",
    "\n",
    "esa_features = df[['severity_cons','dur_cons','util_cons','prin_up','prin_vi','moral_int']].values\n",
    "tau_values = df['CST'].values\n",
    "alpha = np.array([0.4, 0.2, 0.3, 0.0, 0.0, 0.1])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "dnn_baseline_preds = np.zeros(len(X))\n",
    "dnn_override_preds = np.zeros(len(X))\n",
    "dnn_penalized_preds = np.zeros(len(X))\n",
    "\n",
    "def build_dnn_model(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_dim=input_dim),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d5c17b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step\n",
      "Fold 1 - DNN Baseline:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        65\n",
      "           1       1.00      1.00      1.00        89\n",
      "\n",
      "    accuracy                           1.00       154\n",
      "   macro avg       1.00      1.00      1.00       154\n",
      "weighted avg       1.00      1.00      1.00       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[65  0]\n",
      " [ 0 89]]\n",
      "Fold 1 - DNN ESA Override:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        65\n",
      "           1       0.58      1.00      0.73        89\n",
      "\n",
      "    accuracy                           0.58       154\n",
      "   macro avg       0.29      0.50      0.37       154\n",
      "weighted avg       0.33      0.58      0.42       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0 65]\n",
      " [ 0 89]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step\n",
      "Fold 1 - DNN ESA Penalized:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        65\n",
      "           1       1.00      1.00      1.00        89\n",
      "\n",
      "    accuracy                           1.00       154\n",
      "   macro avg       1.00      1.00      1.00       154\n",
      "weighted avg       1.00      1.00      1.00       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[65  0]\n",
      " [ 0 89]]\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "Fold 2 - DNN Baseline:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        65\n",
      "           1       1.00      1.00      1.00        89\n",
      "\n",
      "    accuracy                           1.00       154\n",
      "   macro avg       1.00      1.00      1.00       154\n",
      "weighted avg       1.00      1.00      1.00       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[65  0]\n",
      " [ 0 89]]\n",
      "Fold 2 - DNN ESA Override:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        65\n",
      "           1       0.58      1.00      0.73        89\n",
      "\n",
      "    accuracy                           0.58       154\n",
      "   macro avg       0.29      0.50      0.37       154\n",
      "weighted avg       0.33      0.58      0.42       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0 65]\n",
      " [ 0 89]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step\n",
      "Fold 2 - DNN ESA Penalized:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        65\n",
      "           1       1.00      1.00      1.00        89\n",
      "\n",
      "    accuracy                           1.00       154\n",
      "   macro avg       1.00      1.00      1.00       154\n",
      "weighted avg       1.00      1.00      1.00       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[65  0]\n",
      " [ 0 89]]\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "Fold 3 - DNN Baseline:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        65\n",
      "           1       1.00      0.99      0.99        89\n",
      "\n",
      "    accuracy                           0.99       154\n",
      "   macro avg       0.99      0.99      0.99       154\n",
      "weighted avg       0.99      0.99      0.99       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[65  0]\n",
      " [ 1 88]]\n",
      "Fold 3 - DNN ESA Override:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        65\n",
      "           1       0.58      1.00      0.73        89\n",
      "\n",
      "    accuracy                           0.58       154\n",
      "   macro avg       0.29      0.50      0.37       154\n",
      "weighted avg       0.33      0.58      0.42       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0 65]\n",
      " [ 0 89]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n",
      "Fold 3 - DNN ESA Penalized:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        65\n",
      "           1       1.00      0.99      0.99        89\n",
      "\n",
      "    accuracy                           0.99       154\n",
      "   macro avg       0.99      0.99      0.99       154\n",
      "weighted avg       0.99      0.99      0.99       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[65  0]\n",
      " [ 1 88]]\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "Fold 4 - DNN Baseline:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96        65\n",
      "           1       0.97      0.98      0.97        89\n",
      "\n",
      "    accuracy                           0.97       154\n",
      "   macro avg       0.97      0.97      0.97       154\n",
      "weighted avg       0.97      0.97      0.97       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[62  3]\n",
      " [ 2 87]]\n",
      "Fold 4 - DNN ESA Override:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        65\n",
      "           1       0.58      1.00      0.73        89\n",
      "\n",
      "    accuracy                           0.58       154\n",
      "   macro avg       0.29      0.50      0.37       154\n",
      "weighted avg       0.33      0.58      0.42       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0 65]\n",
      " [ 0 89]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step\n",
      "Fold 4 - DNN ESA Penalized:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        65\n",
      "           1       0.97      1.00      0.98        89\n",
      "\n",
      "    accuracy                           0.98       154\n",
      "   macro avg       0.98      0.98      0.98       154\n",
      "weighted avg       0.98      0.98      0.98       154\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[62  3]\n",
      " [ 0 89]]\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Fold 5 - DNN Baseline:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        64\n",
      "           1       1.00      0.96      0.98        89\n",
      "\n",
      "    accuracy                           0.97       153\n",
      "   macro avg       0.97      0.98      0.97       153\n",
      "weighted avg       0.98      0.97      0.97       153\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[64  0]\n",
      " [ 4 85]]\n",
      "Fold 5 - DNN ESA Override:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        64\n",
      "           1       0.58      1.00      0.74        89\n",
      "\n",
      "    accuracy                           0.58       153\n",
      "   macro avg       0.29      0.50      0.37       153\n",
      "weighted avg       0.34      0.58      0.43       153\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0 64]\n",
      " [ 0 89]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step\n",
      "Fold 5 - DNN ESA Penalized:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        64\n",
      "           1       1.00      0.98      0.99        89\n",
      "\n",
      "    accuracy                           0.99       153\n",
      "   macro avg       0.98      0.99      0.99       153\n",
      "weighted avg       0.99      0.99      0.99       153\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[64  0]\n",
      " [ 2 87]]\n",
      "\n",
      "--- Final Evaluation (DNN Baseline) ---\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       324\n",
      "           1       0.99      0.98      0.99       445\n",
      "\n",
      "    accuracy                           0.99       769\n",
      "   macro avg       0.99      0.99      0.99       769\n",
      "weighted avg       0.99      0.99      0.99       769\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[321   3]\n",
      " [  7 438]]\n",
      "{'accuracy': 0.9869960988296489, 'precision': 0.9931972789115646, 'recall': 0.9842696629213483, 'f1_score': 0.9887133182844243, 'roc_auc': 0.9875052018310445}\n",
      "\n",
      "--- Final Evaluation (DNN ESA Override) ---\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       324\n",
      "           1       0.58      1.00      0.73       445\n",
      "\n",
      "    accuracy                           0.58       769\n",
      "   macro avg       0.29      0.50      0.37       769\n",
      "weighted avg       0.33      0.58      0.42       769\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0 324]\n",
      " [  0 445]]\n",
      "{'accuracy': 0.5786736020806242, 'precision': 0.5786736020806242, 'recall': 1.0, 'f1_score': 0.7331136738056013, 'roc_auc': 0.5}\n",
      "\n",
      "--- Final Evaluation (DNN ESA Penalized) ---\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       324\n",
      "           1       0.99      0.99      0.99       445\n",
      "\n",
      "    accuracy                           0.99       769\n",
      "   macro avg       0.99      0.99      0.99       769\n",
      "weighted avg       0.99      0.99      0.99       769\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[321   3]\n",
      " [  3 442]]\n",
      "{'accuracy': 0.9921976592977894, 'precision': 0.9932584269662922, 'recall': 0.9932584269662922, 'f1_score': 0.9932584269662922, 'roc_auc': 0.9919995838535163}\n",
      "time baseline: 34.129317800001445\n",
      "time override: 0.21336729999893578\n",
      "time penalized: 36.95037250000314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\AISHA AIJAZ\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "b_time = 0\n",
    "o_time = 0\n",
    "p_time = 0\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_scaled, y)):\n",
    "    X_train, X_val = X_scaled.iloc[train_idx], X_scaled.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    b_time_s = time.perf_counter()\n",
    "    # -------- Baseline --------\n",
    "    model_baseline = build_dnn_model(X_train.shape[1])\n",
    "    model_baseline.fit(X_train, y_train, epochs=30, batch_size=32, verbose=0,\n",
    "                           validation_data=(X_val, y_val),\n",
    "                           callbacks=[EarlyStopping(patience=5, restore_best_weights=True)])\n",
    "    y_val_pred_baseline = (model_baseline.predict(X_val).flatten() >= 0.5).astype(int)\n",
    "    dnn_baseline_preds[val_idx] = y_val_pred_baseline\n",
    "    print(f\"Fold {fold+1} - DNN Baseline:\")\n",
    "    evaluate_classification(y_val, y_val_pred_baseline)\n",
    "    b_time_e = time.perf_counter()\n",
    "    b_time = b_time + (b_time_e - b_time_s)\n",
    "\n",
    "    o_time_s = time.perf_counter()\n",
    "    # -------- Override --------\n",
    "    phi_val = esa_features[val_idx]\n",
    "    tau_val = tau_values[val_idx]\n",
    "    esa_vals = np.array([esa_score(phi, alpha) for phi in phi_val])\n",
    "    moral_preds = (esa_vals >= tau_val).astype(int)\n",
    "    dnn_override_preds[val_idx] = moral_preds\n",
    "    print(f\"Fold {fold+1} - DNN ESA Override:\")\n",
    "    evaluate_classification(y_val, moral_preds)\n",
    "    o_time_e = time.perf_counter()\n",
    "    o_time = o_time + (o_time_e - o_time_s)\n",
    "\n",
    "    p_time_s = time.perf_counter()\n",
    "    # -------- Penalized --------\n",
    "    phi_train = esa_features[train_idx]\n",
    "    tau_train = tau_values[train_idx]\n",
    "    moral_penalty = np.array([(tau - esa_score(phi, alpha))**2 for phi, tau in zip(phi_train, tau_train)])\n",
    "    sample_weights = np.clip(1 + 5 * moral_penalty, 1, 10)\n",
    "\n",
    "    model_penalized = build_dnn_model(X_train.shape[1])\n",
    "    model_penalized.fit(X_train, y_train, sample_weight=sample_weights, epochs=30, batch_size=32, verbose=0,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        callbacks=[EarlyStopping(patience=5, restore_best_weights=True)])\n",
    "    y_val_pred_penalized = (model_penalized.predict(X_val).flatten() >= 0.5).astype(int)\n",
    "    dnn_penalized_preds[val_idx] = y_val_pred_penalized\n",
    "    print(f\"Fold {fold+1} - DNN ESA Penalized:\")\n",
    "    evaluate_classification(y_val, y_val_pred_penalized)\n",
    "    p_time_e = time.perf_counter()\n",
    "    p_time = p_time + (p_time_e - p_time_s)\n",
    "\n",
    "print(\"\\n--- Final Evaluation (DNN Baseline) ---\")\n",
    "#evaluate_classification(y, dnn_baseline_preds)\n",
    "metrics = evaluate_classification(y, dnn_baseline_preds)\n",
    "print(metrics)\n",
    "\n",
    "print(\"\\n--- Final Evaluation (DNN ESA Override) ---\")\n",
    "#evaluate_classification(y, dnn_override_preds)\n",
    "metrics = evaluate_classification(y, dnn_override_preds)\n",
    "print(metrics)\n",
    "\n",
    "print(\"\\n--- Final Evaluation (DNN ESA Penalized) ---\")\n",
    "#evaluate_classification(y, dnn_penalized_preds)\n",
    "metrics = evaluate_classification(y, dnn_penalized_preds)\n",
    "print(metrics)\n",
    "\n",
    "print(\"time baseline:\", b_time)\n",
    "print(\"time override:\", o_time)\n",
    "print(\"time penalized:\", p_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61092163",
   "metadata": {},
   "source": [
    "# CVAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85e3857d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import Loss\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c285bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def esa_score(phi, alpha):\n",
    "    return np.dot(alpha, phi)\n",
    "\n",
    "def threshold_crossing_rate(esa_baseline, esa_moral, tau):\n",
    "    crossed = (esa_baseline < tau) & (esa_moral >= tau)\n",
    "    return np.mean(crossed)\n",
    "\n",
    "def moral_win_rate(esa_baseline, esa_moral):\n",
    "    return np.mean(esa_moral > esa_baseline)\n",
    "\n",
    "def esa_difference(esa_baseline, esa_moral):\n",
    "    return np.mean(esa_moral - esa_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9e4761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(y_true, y_pred):\n",
    "    return {\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1': f1_score(y_true, y_pred),\n",
    "        'ROC_AUC': roc_auc_score(y_true, y_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d24ec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVaRLoss(Loss):\n",
    "    def __init__(self, alpha, phi_tensor, tau_tensor, lam=1):\n",
    "        super().__init__()\n",
    "        self.alpha = K.constant(alpha, dtype='float32')\n",
    "        self.phi_tensor = K.constant(phi_tensor, dtype='float32')\n",
    "        self.tau_tensor = K.constant(tau_tensor, dtype='float32')\n",
    "        self.lam = lam\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = K.cast(y_true, dtype='float32')\n",
    "        bce = K.binary_crossentropy(y_true, y_pred)\n",
    "        esa = K.sum(self.phi_tensor * self.alpha, axis=1)\n",
    "        # Penalize low ESA values below CST threshold\n",
    "        tail_penalty = K.relu(self.tau_tensor - esa)\n",
    "        return bce + self.lam * tail_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a07837dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dnn(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_dim=input_dim),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1fc91bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('grad admission - ethics.csv')\n",
    "    \n",
    "y = df['accept_status_moral']\n",
    "X = df.drop(columns=['accept_status', 'ESA', 'CST', 'severity_cons','dur_cons','util_cons','prin_up','prin_vi','moral_int', 'accept_status_moral'])\n",
    "\n",
    "esa_features = df[['severity_cons','dur_cons','util_cons','prin_up','prin_vi','moral_int']].values\n",
    "tau = df['CST'].values\n",
    "phi = df[['severity_cons','dur_cons','util_cons','prin_up','prin_vi','moral_int']].astype('float32').values\n",
    "alpha = np.array([0.4, 0.2, 0.3, 0.0, 0.0, 0.1], dtype='float32')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8285ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "dnn_cvar_preds = np.zeros(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c552d3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "Fold 1 - DNN CVaR Loss:\n",
      "{'Accuracy': 0.5974025974025974, 'Precision': 1.0, 'Recall': 0.30337078651685395, 'F1': 0.46551724137931033, 'ROC_AUC': 0.651685393258427}\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "Fold 2 - DNN CVaR Loss:\n",
      "{'Accuracy': 0.5714285714285714, 'Precision': 1.0, 'Recall': 0.25842696629213485, 'F1': 0.41071428571428575, 'ROC_AUC': 0.6292134831460674}\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "Fold 3 - DNN CVaR Loss:\n",
      "{'Accuracy': 0.5714285714285714, 'Precision': 1.0, 'Recall': 0.25842696629213485, 'F1': 0.41071428571428575, 'ROC_AUC': 0.6292134831460674}\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "Fold 4 - DNN CVaR Loss:\n",
      "{'Accuracy': 0.5064935064935064, 'Precision': 1.0, 'Recall': 0.14606741573033707, 'F1': 0.25490196078431376, 'ROC_AUC': 0.5730337078651685}\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Fold 5 - DNN CVaR Loss:\n",
      "{'Accuracy': 0.5816993464052288, 'Precision': 1.0, 'Recall': 0.2808988764044944, 'F1': 0.4385964912280702, 'ROC_AUC': 0.6404494382022472}\n",
      "Time taken: 19.327241 seconds\n",
      "{'Accuracy': 0.5816993464052288, 'Precision': 1.0, 'Recall': 0.2808988764044944, 'F1': 0.4385964912280702, 'ROC_AUC': 0.6404494382022472}\n"
     ]
    }
   ],
   "source": [
    "#start timer\n",
    "start_time = time.perf_counter()\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_scaled, y)):\n",
    "    X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    phi_train = phi[train_idx]\n",
    "    tau_train = tau[train_idx]\n",
    "\n",
    "    model = build_dnn(X_train.shape[1])\n",
    "    model.compile(optimizer=Adam(0.001), loss=CVaRLoss(alpha, phi_train, tau_train, lam=1.0))\n",
    "    model.fit(X_train, y_train, epochs=30, batch_size=32, verbose=0, callbacks=[EarlyStopping(patience=5, restore_best_weights=True)])\n",
    "    y_val_pred = (model.predict(X_val).flatten() >= 1).astype(int)\n",
    "    dnn_cvar_preds[val_idx] = y_val_pred\n",
    "    print(f\"Fold {fold+1} - DNN CVaR Loss:\")\n",
    "    print(evaluate_classification(y_val, y_val_pred))\n",
    "    \n",
    "end_time = time.perf_counter()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.6f} seconds\")\n",
    "\n",
    "metrics = evaluate_classification(y_val, y_val_pred)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebb8625",
   "metadata": {},
   "source": [
    "# Adversarial Formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89db6778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import Loss\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ead89fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def esa_score(phi, alpha):\n",
    "    return np.dot(phi, alpha)\n",
    "\n",
    "def evaluate_classification(y_true, y_pred):\n",
    "    return {\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1': f1_score(y_true, y_pred),\n",
    "        'ROC_AUC': roc_auc_score(y_true, y_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46cd89ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversary_loss(esa_true, esa_pred):\n",
    "    return K.mean(K.square(esa_true - esa_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "185ee6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_esa_adversary(input_dim):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    x = Dense(32, activation='relu')(inputs)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    esa_output = Dense(1, activation='linear', name='esa_output')(x)\n",
    "    return Model(inputs=inputs, outputs=esa_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e514f4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adversarial_model(input_dim):\n",
    "    # Main classifier\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    x = Dense(64, activation='relu')(input_layer)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output_class = Dense(1, activation='sigmoid', name='class_output')(x)\n",
    "\n",
    "    # ESA adversary\n",
    "    x_esa = Dense(16, activation='relu')(x)\n",
    "    output_esa = Dense(1, activation='linear', name='esa_output')(x_esa)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=[output_class, output_esa])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "942e6b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('credit_risk_dataset - ethics.csv')\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder() \n",
    "\n",
    "# Apply label encoding\n",
    "df['person_home_ownership'] = label_encoder.fit_transform(df['person_home_ownership'])\n",
    "df['loan_intent'] = label_encoder.fit_transform(df['loan_intent'])\n",
    "df['loan_grade'] = label_encoder.fit_transform(df['loan_grade'])\n",
    "df['cb_person_default_on_file'] = label_encoder.fit_transform(df['cb_person_default_on_file'])\n",
    "\n",
    "y = df['loan_status']\n",
    "X = df.drop(columns=['loan_status', 'CST', 'severity_cons','dur_cons','util_cons','prin_up','prin_vi','moral_int'])\n",
    "\n",
    "phi = df[['severity_cons','dur_cons','util_cons','prin_up','prin_vi','moral_int']].astype('float32').values\n",
    "alpha = np.array([0.4, 0.2, 0.3, 0.0, 0.0, 0.1], dtype='float32')\n",
    "ESA_target = esa_score(phi, alpha).reshape(-1, 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6eae28fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "dnn_adv_preds = np.zeros(len(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9cbfd666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 786us/step\n",
      "Fold 1 - ESA Adversarial:\n",
      "{'Accuracy': 0.9053245358293693, 'Precision': 0.9197080291970803, 'Recall': 0.620253164556962, 'F1': 0.7408651826963462, 'ROC_AUC': 0.8025701544080198}\n",
      "204/204 [==============================] - 0s 850us/step\n",
      "Fold 2 - ESA Adversarial:\n",
      "{'Accuracy': 0.9165131982811541, 'Precision': 0.9507186858316222, 'Recall': 0.6511954992967651, 'F1': 0.7729549248747913, 'ROC_AUC': 0.8208863244422577}\n",
      "204/204 [==============================] - 0s 896us/step\n",
      "Fold 3 - ESA Adversarial:\n",
      "{'Accuracy': 0.907305095150399, 'Precision': 0.9225206611570248, 'Recall': 0.6279887482419128, 'F1': 0.7472803347280335, 'ROC_AUC': 0.8066327722363863}\n",
      "204/204 [==============================] - 0s 1ms/step\n",
      "Fold 4 - ESA Adversarial:\n",
      "{'Accuracy': 0.9102209944751382, 'Precision': 0.9106090373280943, 'Recall': 0.6523574947220268, 'F1': 0.7601476014760147, 'ROC_AUC': 0.8172484235141046}\n",
      "204/204 [==============================] - 0s 1ms/step\n",
      "Fold 5 - ESA Adversarial:\n",
      "{'Accuracy': 0.9074585635359116, 'Precision': 0.915650406504065, 'Recall': 0.6340605207600282, 'F1': 0.7492723492723493, 'ROC_AUC': 0.8088850199482183}\n",
      "Time taken: 154.607325 seconds\n",
      "{'Accuracy': 0.9074585635359116, 'Precision': 0.915650406504065, 'Recall': 0.6340605207600282, 'F1': 0.7492723492723493, 'ROC_AUC': 0.8088850199482183}\n"
     ]
    }
   ],
   "source": [
    "#start timer\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_scaled, y)):\n",
    "    X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    ESA_train, ESA_val = ESA_target[train_idx], ESA_target[val_idx]\n",
    "\n",
    "    model = build_adversarial_model(X_train.shape[1])\n",
    "    model.compile(optimizer=Adam(0.001),\n",
    "                  loss={'class_output': 'binary_crossentropy', 'esa_output': 'mse'},\n",
    "                  loss_weights={'class_output': 1.0, 'esa_output': 0.5})\n",
    "\n",
    "    model.fit(X_train, {'class_output': y_train, 'esa_output': ESA_train},\n",
    "              epochs=30, batch_size=32, verbose=0,\n",
    "              validation_split=0.1,\n",
    "              callbacks=[EarlyStopping(patience=5, restore_best_weights=True)])\n",
    "\n",
    "    y_val_pred = (model.predict(X_val)[0].flatten() >= 0.5).astype(int)\n",
    "    dnn_adv_preds[val_idx] = y_val_pred\n",
    "    print(f\"Fold {fold+1} - ESA Adversarial:\")\n",
    "    print(evaluate_classification(y_val, y_val_pred))\n",
    "    \n",
    "end_time = time.perf_counter()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.6f} seconds\")\n",
    "\n",
    "metrics = evaluate_classification(y_val, y_val_pred)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9e83dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
